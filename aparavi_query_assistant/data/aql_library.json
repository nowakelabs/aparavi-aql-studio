{
  "version": "1.0",
  "lastUpdated": "2025-03-24",
  "description": "Consolidated AQL Library with predefined queries for Aparavi Data Suite",
  "categories": [
    {
      "name": "Storage Optimization",
      "description": "# Storage Optimization & Cleanup Queries"
    },
    {
      "name": "Data Inventory",
      "description": "# Data Inventory & Categorization Queries"
    },
    {
      "name": "Security Risk",
      "description": "# Security & Access Risk Queries"
    },
    {
      "name": "Privacy Compliance",
      "description": "# Privacy & Compliance Queries"
    },
    {
      "name": "Governance Lifecycle",
      "description": "# Governance & Lifecycle Management Queries"
    },
    {
      "name": "Email Analysis",
      "description": "# Email Analysis Queries"
    },
    {
      "name": "Content Analytics",
      "description": "# Content Analytics Queries"
    }
  ],
  "queries": [
    {
      "id": "duplicate_file_analysis",
      "title": "Find Duplicate Files",
      "category": "Storage Optimization",
      "purpose": "Identifies files with identical content stored in multiple locations, showing potential storage waste.",
      "query": "SELECT \n  name as \"File Name\", \n  size as \"Size (Bytes)\",\n  size/1048576 as \"Size (MB)\",\n  dupCount as \"Duplicate Count\",\n  parentPath as \"Location\",\n  dupKey as \"Duplicate Key\"\nWHERE \n  dupCount > 1 \n  AND ClassID = 'idxobject'\nORDER BY \n  dupCount DESC, \n  size DESC;",
      "impact": "Reduces storage costs by identifying unnecessary duplicate files that can be consolidated. In typical enterprises, deduplication can free up 15-30% of storage capacity, reducing both infrastructure costs and backup times. IT teams spend less time managing storage expansion, while users benefit from a cleaner file system without redundant copies.",
      "action": "Review duplicates and implement deduplication policies for the highest impact files...",
      "verified": true,
      "keywords": [
        "file deduplication",
        "file copies",
        "cleanup",
        "detect duplicates"
      ],
      "visualization": false,
      "modified": "2025-04-10T17:59:15.619675"
    },
    {
      "id": "large_files_identification",
      "title": "Find Large Files",
      "category": "Storage Optimization",
      "purpose": "Locates extremely large files that may be consuming disproportionate storage.",
      "query": "SELECT \n  parentPath as \"Path\",\n  name as \"File Name\", \n  extension as \"Extension\",\n  size as \"Size (Bytes)\",\n  size/1048576 as \"Size (MB)\",\n  createTime as \"Created\",\n  modifyTime as \"Last Modified\"\nWHERE \n  size > 100000000 -- 100MB\n  AND ClassID = 'idxobject'\nORDER BY \n  size DESC;",
      "impact": "Often, just 1-2% of files consume more than 30% of total storage. Identifying these \"storage hogs\" allows for targeted optimization, significantly reducing cloud storage costs and backup times. For users, this translates to faster system performance and less time waiting for large files to open or transfer.",
      "action": "Review large files to determine if they can be compressed, archived, or deleted.",
      "keywords": [
        "large files",
        "big files",
        "storage hogs",
        "file size",
        "biggest files"
      ],
      "verified": true,
      "visualization": false,
      "modified": "2025-04-10T18:11:21.939718"
    },
    {
      "id": "long_term_stale_data",
      "title": "Find Old Unused Files",
      "category": "Storage Optimization",
      "purpose": "Identifies files that haven't been accessed or modified in over 2 years, making them candidates for archival.",
      "query": "-- Query uses date template variables which will be automatically replaced with actual dates\n-- based on the current date when the query is executed.\n-- As of today (2025-03-25), {{DATE_MINUS_2_YEARS}} = 2023-03-25\nSELECT \n  parentPath as \"Path\",\n  name as \"File Name\", \n  extension as \"Extension\",\n  size as \"Size (Bytes)\",\n  size/1048576 as \"Size (MB)\",\n  modifyTime as \"Last Modified\",\n  osOwner as \"Owner\"\nWHERE \n  (modifyTime < '{{DATE_MINUS_2_YEARS}}') -- Files older than 2 years\n  AND (ClassID = 'idxobject')\nORDER BY \n  \"Last Modified\" ASC,\n  \"Size (Bytes)\" DESC;",
      "impact": "Archiving stale data can reduce primary storage costs by 50-70% by moving rarely-accessed files to lower-cost storage tiers. This improves system performance while maintaining data availability when needed. Business users gain faster search results and easier navigation without the clutter of outdated files, while still retaining access to historical data when required.",
      "action": "Consider moving these files to cold storage or initiating a review for deletion.",
      "verified": true,
      "keywords": [
        "old",
        "stale",
        "age",
        "archive"
      ],
      "modified": "2025-04-10T18:16:03.698681"
    },
    {
      "id": "large_and_inactive_files_high_impact_cleanup",
      "title": "Big Unused Files for Quick Savings",
      "category": "Storage Optimization",
      "purpose": "Targets files that are both large (>100MB) and haven't been modified in at least 1 year - these represent the highest-impact cleanup opportunities.",
      "query": "-- Query uses date template variables which will be automatically replaced with actual dates\n-- based on the current date when the query is executed.\n-- As of today (2025-03-25), {{DATE_MINUS_1_YEAR}} = 2024-03-25\nSELECT \n  parentPath as \"Path\",\n  name as \"File Name\", \n  extension as \"Extension\",\n  size as \"Size (Bytes)\",\n  size/1048576 as \"Size (MB)\",\n  modifyTime as \"Last Modified\"\nWHERE \n  (size > 100000000) -- 100MB\n  AND (modifyTime < '{{DATE_MINUS_1_YEAR}}') -- Files older than 1 year (2024-03-25)\n  AND (ClassID = 'idxobject')\nORDER BY \n  \"Size (Bytes)\" DESC;",
      "impact": "This focused approach typically yields the highest ROI for cleanup efforts, often identifying 5-10% of data volume that can be immediately archived, reducing storage costs with minimal business impact. IT departments can show quick wins and measurable cost savings to leadership, while users experience faster system performance without losing valuable content.",
      "action": "These are prime candidates for immediate archival or defensible deletion.",
      "verified": true,
      "visualization": false,
      "keywords": [
        "large files",
        "big files",
        "storage hogs",
        "file size",
        "biggest files",
        "old",
        "stale",
        "age",
        "archive",
        "quick saving"
      ],
      "modified": "2025-04-10T18:19:50.461274"
    },
    {
      "id": "temporary_low_value_files",
      "title": "Find Temporary and Backup Files",
      "category": "Storage Optimization",
      "purpose": "Locates temporary, backup, or log files that often accumulate but provide little long-term value.",
      "query": "-- Query uses date template variables which will be automatically replaced with actual dates\n-- based on the current date when the query is executed.\n-- As of today (2025-03-25), {{DATE_MINUS_90_DAYS}} = 2024-12-25\nSELECT \n  parentPath as \"Path\",\n  name as \"File Name\", \n  extension as \"Extension\",\n  size as \"Size (Bytes)\",\n  size/1048576 as \"Size (MB)\",\n  modifyTime as \"Last Modified\"\nWHERE \n  ((extension IN ('tmp','log','bak','temp')) OR (name LIKE '%bak%') OR (name LIKE '%backup%') OR (name LIKE '%tmp%') OR (name LIKE '%temp%'))\n  AND (modifyTime < '{{DATE_MINUS_90_DAYS}}') -- Files older than 3 months (2024-12-25)\n  AND (ClassID = 'idxobject')\nORDER BY \n  \"Size (Bytes)\" DESC;",
      "impact": "Temporary files often account for 10-15% of total storage but provide zero business value after their immediate use. Automated cleanup reduces storage costs and eliminates potential confusion caused by outdated temporary files. System administrators spend less time troubleshooting issues related to disk space, and developers avoid errors caused by accumulated temporary files.",
      "action": "Consider implementing automated cleanup policies for these file types.",
      "verified": true,
      "visualization": false,
      "keywords": [
        "temp files",
        "backup files",
        "log files"
      ],
      "modified": "2025-04-10T18:29:13.358229"
    },
    {
      "id": "zero_byte_files",
      "title": "Find Empty Files",
      "category": "Storage Optimization",
      "purpose": "Identifies empty files that serve no purpose but clutter the file system.",
      "query": "SELECT \n  parentPath as \"Path\",\n  name as \"File Name\", \n  extension as \"Extension\",\n  modifyTime as \"Last Modified\"\nWHERE \n  size = 0\n  AND ClassID = 'idxobject'\nORDER BY \n  modifyTime DESC;",
      "impact": "While zero-byte files don't significantly impact storage capacity, they create index bloat and confusion for users. Removing them improves system performance and searchability. Users no longer encounter \"empty\" files that waste time when opened, and IT reduces the number of help desk tickets related to corrupted or incomplete files.",
      "action": "Empty files can generally be safely deleted after review.",
      "verified": true,
      "visualization": false,
      "keywords": [
        "empty",
        "zero size",
        "zero byte"
      ],
      "modified": "2025-04-10T18:33:07.090007"
    },
    {
      "id": "storage_hogs_by_directory",
      "title": "Folders Using Most Storage",
      "category": "Storage Optimization",
      "purpose": "Identifies the directories consuming the most storage to focus cleanup efforts.",
      "query": "SELECT \n  parentPath as \"Directory Path\",\n  COUNT(name) as \"File Count\",\n  SUM(size) as \"Total Size (Bytes)\",\n  SUM(size)/1048576 as \"Total Size (MB)\",\n  AVG(size)/1048576 as \"Average File Size (MB)\"\nWHERE \n  ClassID = 'idxobject'\nGROUP BY \n  parentPath\nORDER BY \n  SUM(size) DESC;",
      "impact": "Typically, 20% of directories contain 80% of data volume. This analysis enables targeted cleanup efforts with business owners of specific directories, maximizing efficiency and minimizing disruption. Department managers gain visibility into their team's storage usage, enabling better management of digital assets and more accurate budgeting for storage needs.",
      "action": "Focus cleanup efforts on the top storage-consuming directories.",
      "verified": true,
      "visualization": false,
      "keywords": [
        "large folders",
        "big folders",
        "large files",
        "big files"
      ],
      "modified": "2025-04-10T18:38:06.983994"
    },
    {
      "id": "storage_by_file_age_buckets",
      "title": "Storage by File Age Groups",
      "category": "Storage Optimization",
      "purpose": "Shows how storage is distributed across different age buckets to understand if older data is consuming significant space.",
      "query": "-- Query uses date template variables which will be automatically replaced with actual dates\n-- based on the current date when the query is executed.\n-- As of today (2025-03-25):\n--   {{DATE_MINUS_90_DAYS}} = 2024-12-25 (Last 3 Months)\n--   {{DATE_MINUS_1_YEAR}} = 2024-03-25 (3-12 Months)\n--   {{DATE_MINUS_3_YEARS}} = 2022-03-25 (1-3 Years)\nSELECT \n  CASE \n    WHEN createTime >= '{{DATE_MINUS_90_DAYS}}' THEN 'Last 3 Months'\n    WHEN createTime >= '{{DATE_MINUS_1_YEAR}}' THEN '3-12 Months'\n    WHEN createTime >= '{{DATE_MINUS_3_YEARS}}' THEN '1-3 Years'\n    ELSE 'Older than 3 Years'\n  END as \"Age Bucket\",\n  COUNT(name) as \"File Count\",\n  SUM(size) as \"Total Size (Bytes)\",\n  SUM(size)/1048576 as \"Total Size (MB)\"\nWHERE \n  (ClassID = 'idxobject')\nGROUP BY \n\"Age Bucket\",\ncase \"Age Bucket\" \n  when  'Last 3 Months' then 1 \n  when  '3-12 Months' then 2 \n  when  '1-3 Years' then 3 \nelse 4 end\nORDER BY \ncase \"Age Bucket\" \n  when  'Last 3 Months' then 1 \n  when  '3-12 Months' then 2 \n  when  '1-3 Years' then 3 \nelse 4 end\n;",
      "impact": "This analysis enables tiered storage strategies that can reduce overall storage costs by 40-60% by aligning storage performance with actual usage patterns. Organizations can implement automated lifecycle policies based on data age, reducing manual management overhead. Legal and compliance teams gain better visibility into aging data that may be subject to retention policies.",
      "action": "Apply age-based data lifecycle policies to move older data to cheaper storage tiers.",
      "verified": true,
      "visualization": false,
      "keywords": [
        "aging",
        "buckets",
        "old and large files"
      ],
      "modified": "2025-04-10T18:52:51.136858"
    },
    {
      "id": "rot_data_summaryDupes",
      "title": "ROT Files - Duplicates",
      "category": "Storage Optimization",
      "purpose": "Provides a high-level summary of potential ROT (Redundant, Obsolete, Trivial) data across the estate.",
      "query": "-- Query uses date template variables which will be automatically replaced with actual dates\n-- based on the current date when the query is executed.\n-- As of today (2025-03-25), {{DATE_MINUS_2_YEARS}} = 2023-03-25\n\n-- Query to analyze redundant, obsolete, and trivial (ROT) data\n-- Fixed for Aparavi API compatibility\nSELECT \n  'Duplicate Files' as \"ROT Category\",\n  COUNT (name) as \"File Count\",\n  SUM(size * (dupCount - 1)) as \"Wasted Bytes\",\n  SUM(size * (dupCount - 1))/1048576 as \"Wasted MB\"\nWHERE \n  (dupCount > 1)\n  AND (ClassID = 'idxobject')\ngroup by \"ROT Category\";",
      "impact": "This executive-level summary provides a clear ROI calculation for data cleanup initiatives, typically showing that 30-50% of storage is consumed by ROT data. This builds organizational support for governance initiatives and demonstrates tangible cost savings. CIOs and IT directors can use this data to justify investments in data management tools and resources.",
      "action": "Use this summary to set cleanup priorities and tracking progress over time.",
      "verified": true,
      "visualization": false,
      "keywords": [
        "ROT Data",
        "Redundant Obsolete Trivial",
        "File System Cleanup",
        "Data Governance",
        "Storage Optimization",
        "ROI Calculation",
        "Obsolete Files",
        "File Age Analysis",
        "Cleanup Priorities",
        "Storage Utilization",
        "Cost Savings",
        "Data Retention Policies"
      ],
      "modified": "2025-04-13T09:58:11.279181"
    },
    {
      "id": "rot_data_summaryOld",
      "title": "ROT Files - Obsolete",
      "category": "Storage Optimization",
      "purpose": "Provides a high-level summary of potential ROT (Redundant, Obsolete, Trivial) data across the estate.",
      "query": "-- Query uses date template variables which will be automatically replaced with actual dates\n-- based on the current date when the query is executed.\n-- As of today (2025-03-25), {{DATE_MINUS_2_YEARS}} = 2023-03-25\n\n-- Query to analyze redundant, obsolete, and trivial (ROT) data\n-- Fixed for Aparavi API compatibility\nSELECT \n  'Obsolete Files (>2 years old)' as \"ROT Category\",\n  COUNT(name) as \"File Count\",\n  SUM(size) as \"Total Bytes\",\n  SUM(size)/1048576 as \"Total MB\"\nWHERE \n  (modifyTime < '{{DATE_MINUS_2_YEARS}}') -- Files older than 2 years\n  AND (ClassID = 'idxobject')\ngroup by \"ROT Category\"",
      "impact": "This executive-level summary provides a clear ROI calculation for data cleanup initiatives, typically showing that 30-50% of storage is consumed by ROT data. This builds organizational support for governance initiatives and demonstrates tangible cost savings. CIOs and IT directors can use this data to justify investments in data management tools and resources.",
      "action": "Use this summary to set cleanup priorities and tracking progress over time.",
      "verified": true,
      "visualization": false,
      "keywords": [
        "ROT Data",
        "Redundant Obsolete Trivial",
        "File System Cleanup",
        "Data Governance",
        "Storage Optimization",
        "ROI Calculation",
        "Obsolete Files",
        "File Age Analysis",
        "Cleanup Priorities",
        "Storage Utilization",
        "Cost Savings",
        "Data Retention Policies"
      ],
      "modified": "2025-04-13T09:58:46.232126"
    },
    {
      "id": "rot_data_summaryTrivial",
      "title": "ROT Files - Trivial",
      "category": "Storage Optimization",
      "purpose": "Provides a high-level summary of potential ROT (Redundant, Obsolete, Trivial) data across the estate.",
      "query": "-- Query uses date template variables which will be automatically replaced with actual dates\n-- based on the current date when the query is executed.\n-- As of today (2025-03-25), {{DATE_MINUS_2_YEARS}} = 2023-03-25\n\n-- Query to analyze redundant, obsolete, and trivial (ROT) data\n-- Fixed for Aparavi API compatibility\nSELECT \n  'Trivial Files (temps, logs, etc)' as \"ROT Category\",\n  COUNT(name) as \"File Count\",\n  SUM(size) as \"Total Bytes\",\n  SUM(size)/1048576 as \"Total MB\"\nWHERE \n  ((extension IN ('tmp','log','bak','temp')) OR (name LIKE '%temp%'))\n  AND (ClassID = 'idxobject')\ngroup by \"ROT Category\"",
      "impact": "This executive-level summary provides a clear ROI calculation for data cleanup initiatives, typically showing that 30-50% of storage is consumed by ROT data. This builds organizational support for governance initiatives and demonstrates tangible cost savings. CIOs and IT directors can use this data to justify investments in data management tools and resources.",
      "action": "Use this summary to set cleanup priorities and tracking progress over time.",
      "verified": true,
      "visualization": false,
      "keywords": [
        "ROT Data",
        "Redundant Obsolete Trivial",
        "File System Cleanup",
        "Data Governance",
        "Storage Optimization",
        "ROI Calculation",
        "Obsolete Files",
        "File Age Analysis",
        "Cleanup Priorities",
        "Storage Utilization",
        "Cost Savings",
        "Data Retention Policies"
      ],
      "modified": "2025-04-13T09:59:24.608648"
    },
    {
      "id": "storage_source_distribution",
      "title": "Where Is My Data Stored",
      "category": "Data Inventory",
      "purpose": "Provides a high-level breakdown of data volumes across different storage repositories.",
      "query": "SELECT \n  service as \"Storage Source\",\n  COUNT(name) as \"File Count\",\n  SUM(size) as \"Total Size (Bytes)\",\n  SUM(size)/1048576 as \"Total Size (MB)\"\nWHERE \n  ClassID = 'idxobject'\nGROUP BY \n  service\nORDER BY \n  SUM(size) DESC;",
      "impact": "This high-level view enables accurate infrastructure planning and budgeting for storage resources. IT leadership can effectively allocate resources based on actual data distribution rather than estimates. For departmental managers, this visibility helps justify data management initiatives and establish realistic governance scopes, reducing project overruns by 20-30%.",
      "action": "Identify storage platforms with the highest volumes for targeted optimization.",
      "keywords": [
        "storage sources",
        "repositories",
        "storage distribution",
        "storage locations",
        "data volume"
      ],
      "verified": true,
      "visualization": false
    },
    {
      "id": "file_type_distribution_analysis",
      "title": "File Extensions and Types",
      "category": "Data Inventory",
      "purpose": "Categorizes data by file type/extension to understand what kinds of files dominate your environment.",
      "query": "SELECT \n  CASE \n    WHEN extension IS NULL THEN 'No Extension'\n    WHEN extension = '' THEN 'No Extension'\n    ELSE extension \n  END as \"File Type\",\n  COUNT(name) as \"File Count\",\n  SUM(size) as \"Total Size (Bytes)\",\n  SUM(size)/1048576 as \"Total Size (MB)\",\n  AVG(size)/1048576 as \"Average File Size (MB)\",\n  MIN(size)/1048576 as \"Smallest File (MB)\",\n  MAX(size)/1048576 as \"Largest File (MB)\"\nWHERE \n  ClassID = 'idxobject'\nGROUP BY \n \"File Type\" \nORDER BY \n  SUM(size) DESC;",
      "impact": "Organizations typically discover that 15-25% of files reside in inappropriate locations, causing confusion and inefficient searches. This analysis helps IT teams standardize content repositories, reducing the time employees spend searching for information by up to 30%. End users experience faster searches and more reliable results, increasing productivity and reducing frustration.",
      "action": "Identify unexpected file types and develop type-specific management strategies.",
      "verified": true,
      "keywords": [
        "file extensions",
        "extensions",
        "file types",
        "extension counts",
        "file format"
      ],
      "visualization": false
    },
    {
      "id": "file_size_distribution",
      "title": "Files by Size Categories",
      "category": "Data Inventory",
      "purpose": "Segments files into logical size categories to understand the distribution profile.",
      "query": "SELECT \n  CASE \n    WHEN size = 0 THEN '1. Empty (0 Bytes)'\n    WHEN size < 10240 THEN '2. Tiny (<10 KB)'\n    WHEN size < 1048576 THEN '3. Small (10 KB - 1 MB)'\n    WHEN size < 10485760 THEN '4. Medium (1-10 MB)'\n    WHEN size < 104857600 THEN '5. Large (10-100 MB)'\n    WHEN size < 1073741824 THEN '6. Very Large (100 MB - 1 GB)'\n    ELSE '7. Huge (>1 GB)'\n  END as \"Size Category\",\n  COUNT(name) as \"File Count\",\n  SUM(size) as \"Total Size (Bytes)\",\n  SUM(size)/1048576 as \"Total Size (MB)\"\nWHERE \n  ClassID = 'idxobject'\nGROUP BY \n  \"Size Category\" \nORDER BY \n  \"Size Category\";",
      "impact": "Size distribution analysis typically reveals that a small percentage of files (5-10%) consumes the majority of storage (60-70%). This knowledge allows targeted cleanup efforts with maximum impact for minimal effort. IT teams can focus remediation efforts on specific size categories rather than attempting broad cleanup initiatives, improving success rates and reducing disruption.",
      "action": "Target the size categories consuming disproportionate storage for cleanup actions.",
      "keywords": [
        "file size",
        "size categories",
        "size distribution",
        "file sizes",
        "storage consumption"
      ],
      "verified": true,
      "visualization": false
    },
    {
      "id": "age_profile_by_creation_year",
      "title": "File Age by Creation Year",
      "category": "Data Inventory",
      "purpose": "Analyzes file creation dates to understand the age profile of your data estate.",
      "query": "SELECT \n  YEAR(createTime) as \"Creation Year\",\n  COUNT(name) as \"File Count\",\n  SUM(size) as \"Total Size (Bytes)\",\n  SUM(size)/1048576 as \"Total Size (MB)\",\n  AVG(size) as \"Average File Size (Bytes)\"\nWHERE \n  ClassID = 'idxobject'\nGROUP BY \n  YEAR(createTime)\nORDER BY \n  YEAR(createTime) DESC;",
      "impact": "Understanding the age profile of data enables appropriate archiving and retention policies. Organizations can reduce storage costs by 30-40% through automated lifecycle management based on accurate age profiles. This improves compliance with retention policies while ensuring historical data remains accessible when needed. Legal and compliance teams gain confidence in defensible deletion practices.",
      "action": "Establish data lifecycle policies based on age distribution patterns.",
      "verified": true,
      "keywords": [
        "file age",
        "creation date"
      ],
      "visualization": false
    },
    {
      "id": "data_distribution_by_known_owner",
      "title": "File Ownership Distribution",
      "category": "Data Inventory",
      "purpose": "Summarizes file ownership across the enterprise to understand user data footprints.",
      "query": "SELECT \n  CASE \n    WHEN osOwner IS NULL THEN 'Unowned'\n    WHEN osOwner = '' THEN 'Unowned'\n    ELSE osOwner \n  END as \"Owner\",\n  COUNT(name) as \"File Count\",\n  SUM(size) as \"Total Size (Bytes)\",\n  SUM(size)/1048576 as \"Total Size (MB)\",\n  AVG(size) as \"Average File Size (Bytes)\"\nWHERE \n  ClassID = 'idxobject'\nGROUP BY \n  \"Owner\" \nORDER BY \n  SUM(size) DESC;",
      "impact": "When employees change roles or leave the organization, orphaned files create security risks and waste storage. This analysis helps HR and IT work together to ensure proper data transfer during transitions, reducing security incidents by 15-20%. Incoming employees find relevant information faster, reducing onboarding time and improving productivity.",
      "action": "Focus data governance outreach on users with the largest data footprints.",
      "verified": true,
      "keywords": [
        "file owner",
        "ownership"
      ],
      "visualization": false
    },
    {
      "id": "file_classification_distribution",
      "title": "Sensitive vs Non-Sensitive Files",
      "category": "Data Inventory",
      "purpose": "Provides a breakdown of data by classification labels to understand sensitivity distribution.",
      "query": "SELECT \n  CASE \n    WHEN classification IS NULL THEN 'Unclassified'\n    WHEN classification = '' THEN 'Unclassified'\n    ELSE classification \n  END as \"Classification\",\n  COUNT(name) as \"File Count\",\n  SUM(size) as \"Total Size (Bytes)\",\n  SUM(size)/1048576 as \"Total Size (MB)\"\nWHERE \n  ClassID = 'idxobject'\nGROUP BY \n \"Classification\" \nORDER BY \n  COUNT(name) DESC;",
      "impact": "File extension analysis typically reveals that 60-80% of storage is consumed by just 5-10 file types. This knowledge allows targeted governance policies rather than one-size-fits-all approaches, reducing policy enforcement overhead by 30-50%. Users experience more relevant and less intrusive governance controls, increasing compliance rates.",
      "action": "Review classification coverage and ensure sensitive data is properly identified.",
      "verified": true,
      "keywords": [
        "file classification",
        "sensitive data",
        "pii data"
      ],
      "visualization": false
    },
    {
      "id": "path_depth_analysis",
      "title": "Folder Structure Complexity",
      "category": "Data Inventory",
      "purpose": "Analyzes how deeply files are nested in the directory structure, often indicating complexity issues.",
      "query": "SELECT \n  CASE\n    WHEN parentPath NOT LIKE '%/%' THEN '00 - Root Level'\n    WHEN parentPath LIKE '/%' AND parentPath NOT LIKE '%/%/%' THEN '01'\n    WHEN parentPath LIKE '/%/%' AND parentPath NOT LIKE '%/%/%/%' THEN '02'\n    WHEN parentPath LIKE '/%/%/%' AND parentPath NOT LIKE '%/%/%/%/%' THEN '03'\n    WHEN parentPath LIKE '/%/%/%/%' AND parentPath NOT LIKE '%/%/%/%/%/%' THEN '04'\n    WHEN parentPath LIKE '/%/%/%/%/%' AND parentPath NOT LIKE '%/%/%/%/%/%/%' THEN '05'\n    WHEN parentPath LIKE '/%/%/%/%/%/%' AND parentPath NOT LIKE '%/%/%/%/%/%/%/%' THEN '06'\n    WHEN parentPath LIKE '/%/%/%/%/%/%/%' AND parentPath NOT LIKE '%/%/%/%/%/%/%/%/%' THEN '07'\n    WHEN parentPath LIKE '/%/%/%/%/%/%/%/%' AND parentPath NOT LIKE '%/%/%/%/%/%/%/%/%/%' THEN '08'\n    WHEN parentPath LIKE '/%/%/%/%/%/%/%/%/%' AND parentPath NOT LIKE '%/%/%/%/%/%/%/%/%/%/%' THEN '09'\n    WHEN parentPath LIKE '/%/%/%/%/%/%/%/%/%/%' AND parentPath NOT LIKE '%/%/%/%/%/%/%/%/%/%/%/%' THEN '10'\n    ELSE '11+'\n  END as \"Directory Depth\",\n  COUNT(name) as \"File Count\",\n  MIN(LENGTH(parentPath)) as \"Min Path Length (Characters)\",\n  AVG(LENGTH(parentPath)) as \"Average Path Length (Characters)\",\n  MAX(LENGTH(parentPath)) as \"Max Path Length (Characters)\"\nWHERE \n  ClassID = 'idxobject'\nGROUP BY \n  \"Directory Depth\"\nORDER BY \n  \"Directory Depth\";",
      "impact": "Complex directory structures increase access time and create confusion for users. Analyzing and optimizing path depths can improve system performance by 10-15% and reduce user errors by 20-25%. IT support sees fewer tickets related to file location issues, while users spend less time navigating complex folder hierarchies and more time on productive work.",
      "action": "Identify excessively deep directory structures that may need reorganization.",
      "verified": true,
      "keywords": [
        "paths",
        "folder depth",
        "directory structure",
        "location"
      ],
      "modified": "2025-04-11T15:15:56.950857"
    },
    {
      "id": "data_hotspots_by_directory",
      "title": "Folders with Most Files",
      "category": "Data Inventory",
      "purpose": "Identifies directories with the highest concentration of files to understand storage patterns.",
      "query": "SELECT \n  parentPath as \"Directory Path\",\n  COUNT(name) as \"File Count\",\n  SUM(size) as \"Total Size (Bytes)\",\n  SUM(size)/1048576 as \"Total Size (MB)\",\n  MAX(size)/1048576 as \"Largest File (MB)\",\n  MIN(size)/1048576 as \"Smallest File (MB)\",\n  AVG(size)/1048576 as \"Average File Size (MB)\"\nWHERE \n  ClassID = 'idxobject'\nGROUP BY \n  parentPath\nHAVING \n  \"File Count\" > 100\nORDER BY \n  \"File Count\" DESC;",
      "impact": "High-density directories often become information bottlenecks, creating access conflicts and version control issues. By identifying and addressing these hotspots, organizations can improve collaborative workflows and reduce file access times by 15-25%. Project teams experience fewer file locking conflicts and more efficient collaboration.",
      "action": "Target high-density directories for optimization and cleanup.",
      "verified": true,
      "visualization": false,
      "keywords": [
        "many folders",
        "most files"
      ],
      "modified": "2025-04-11T15:19:59.472888"
    },
    {
      "id": "file_type_trend_analysis",
      "title": "File Type Usage Over Time",
      "category": "Data Inventory",
      "purpose": "Examines how file type distribution has changed over time to identify trends.",
      "query": "-- Note: Since AQL doesn't support complex subqueries, focus on common file types instead\nSELECT \n  extension as \"File Type\",\n  YEAR(createTime) as \"Year\",\n  COUNT(name) as \"File Count\",\n  SUM(size)/1048576 as \"Total Size (MB)\"\nWHERE \n  ClassID = 'idxobject'\n  AND extension IN ('docx', 'xlsx', 'pdf', 'jpg', 'png', 'txt', 'pptx', 'csv', 'zip', 'html')\nGROUP BY \n  extension, YEAR(createTime)\nORDER BY \n  extension, YEAR(createTime);",
      "impact": "Understanding trends in file usage helps organizations anticipate future storage and application needs. IT departments can proactively implement support for emerging file formats, reducing compatibility issues by 30-40%. End users can utilize new file formats with confidence that they'll be properly supported, enabling adoption of more efficient workflows and technologies.",
      "action": "Identify emerging file types and develop appropriate management strategies.",
      "verified": true,
      "visualization": false,
      "keywords": [
        "file type over time",
        "document by year"
      ],
      "modified": "2025-04-11T15:25:40.047207"
    },
    {
      "id": "executable_files_summary_report",
      "title": "Find Executable Files",
      "category": "Security Risk",
      "purpose": "Provides a high-level summary of executable and script files by type and location to quickly identify potential risk areas when dealing with large numbers of files.",
      "query": "SELECT \n  extension as \"File Type\",\n  COUNT(name) as \"File Count\",\n  SUM(size)/1048576 as \"Total Size (MB)\",\n  -- Using basic date functions for better readability\n  CONCAT(YEAR(MAX(modifyTime)), '-', MONTH(MAX(modifyTime)), '-', DAY(MAX(modifyTime))) as \"Most Recent Modified Date\"\nWHERE \n  extension IN ('exe','dll','bat','sh','ps1','vbs','js','py')\n  AND ClassID = 'idxobject'\nGROUP BY\n  extension\nORDER BY \n  COUNT(name) DESC;",
      "impact": "This summary report enables security teams to quickly identify anomalies across thousands of executable files. Organizations can prioritize investigation efforts on the most prevalent high-risk file types, reducing time to remediation by 30-40%. This approach allows security teams to allocate resources more effectively based on actual risk distribution rather than conducting unfocused scans.",
      "action": "Identify file types with unexpected counts or recent modifications for further investigation using the detailed report.",
      "verified": true,
      "visualization": false
    },
    {
      "id": "high_confidence_security_classifications_report",
      "title": "Confirmed Security Issues",
      "category": "Security Risk",
      "purpose": "Provides a filtered view of files with high-confidence security-related classifications to focus remediation on the most reliable findings.",
      "query": "SELECT \n  classification as \"Classification\",\n  confidence as \"Confidence Score\",\n  COUNT(name) as \"File Count\",\n  SUM(size)/1048576 as \"Total Size (MB)\",\n  CONCAT(YEAR(MAX(modifyTime)), '-', MONTH(MAX(modifyTime)), '-', DAY(MAX(modifyTime))) as \"Most Recent Modified Date\"\nWHERE \n  (classification LIKE '%Authentication Policy%'\n   OR classification LIKE '%Ransomware Policy%'\n   OR classification LIKE '%IP Address Policy%'\n   OR classification LIKE '%Company Confidential%')\n  -- Only include classifications with a high confidence (85 or higher)\n  AND confidence >= 85\n  AND ClassID = 'idxobject'\nGROUP BY\n  classification,\n  confidence\nORDER BY \n  confidence DESC,\n  \"File Count\" DESC;",
      "impact": "Focusing on high-confidence security classifications reduces false positives by 40-60% compared to unfiltered results, enabling security teams to remediate actual risks faster. Organizations report up to 75% improvement in security scanning efficiency when prioritizing by classification confidence. This approach significantly reduces alert fatigue and allows security resources to focus on genuine threats rather than marginal cases.",
      "action": "Review and remediate files with high-confidence security classification findings, especially those with recent modification dates.",
      "verified": true,
      "visualization": false,
      "keywords": [
        "security classifications",
        "high risk",
        "ip",
        "ransomware",
        "confidential"
      ],
      "modified": "2025-04-11T15:37:28.055340"
    },
    {
      "id": "executable_files_location_summary",
      "title": "Where Are Executable Files Located",
      "category": "Security Risk",
      "purpose": "Groups executable files by location to identify directories with high concentrations of potentially risky files.",
      "query": "SELECT \n  parentPath as \"Directory\",\n  COUNT(name) as \"Executable Count\",\n  SUM(size)/1048576 as \"Total Size (MB)\",\n  -- Using basic date functions for better readability\n  CONCAT(YEAR(MAX(modifyTime)), '-', MONTH(MAX(modifyTime)), '-', DAY(MAX(modifyTime))) as \"Most Recent Modified Date\"\nWHERE \n  extension IN ('exe','dll','bat','sh','ps1','vbs','js','py')\n  AND ClassID = 'idxobject'\nGROUP BY\n  parentPath\nORDER BY \n  COUNT(name) DESC;",
      "impact": "Identifying directories with high concentrations of executables helps organizations detect unauthorized application installations, malware distribution points, and policy violations. Security teams can reduce attack surface by 50-70% by focusing on high-risk directories. System administrators can implement appropriate access controls on these locations, while security teams can prioritize scanning based on actual risk distribution.",
      "action": "Investigate directories with unusually high executable counts or containing unexpected file types.",
      "verified": true,
      "visualization": false,
      "keywords": [
        "executable",
        "unauthorized install",
        "malware",
        "policy violations"
      ],
      "modified": "2025-04-11T15:41:33.573754"
    },
    {
      "id": "executable_files_detailed_report",
      "title": "Executable Files Detailed Report",
      "category": "Security Risk",
      "purpose": "Provides a detailed view of individual executable and script files for in-depth investigation after identifying areas of concern in the summary reports.",
      "query": "SELECT \n  parentPath as \"Path\",\n  name as \"File Name\", \n  extension as \"Extension\",\n  size/1048576 as \"Size (MB)\",\n  osOwner as \"Owner\",\n  CONCAT(YEAR(modifyTime), '-', MONTH(modifyTime), '-', DAY(modifyTime)) as \"Last Modified\"\nWHERE \n  (extension IN ('exe','dll','bat','sh','ps1','vbs','js','py')\n  AND ClassID = 'idxobject')\n  -- Add additional filters based on summary findings, for example:\n  -- AND parentPath LIKE '/suspicious/directory/%'\n  -- AND extension = 'ps1'\nORDER BY \n  \"Last Modified\" DESC;",
      "impact": "Unauthorized executable files are involved in 70-80% of security breaches. This detailed report helps security teams investigate specific files identified as suspicious in the summary reports. Organizations typically reduce malware incidents by 40-60% when implementing regular executable discovery and verification. For end users, this means fewer system disruptions, less downtime from remediation, and lower risk of data loss.",
      "action": "Review specific executable files against allowed application inventory and scan for malware. Uncomment and modify the suggested filters to focus on areas identified in the summary reports.",
      "verified": true,
      "visualization": false,
      "keywords": [
        "Executable Files",
        "Script Files",
        "Detailed Investigation",
        "Security Breaches",
        "Unauthorized Executables",
        "Malware Incidents",
        "System Disruptions",
        "Data Loss Prevention",
        "Remediation Downtime",
        "Executable Discovery",
        "File Verification",
        "Allowed Application Inventory",
        "Malware Scanning",
        "Suspicious Files",
        "Regular Audits"
      ]
    },
    {
      "id": "files_with_suspicious_names",
      "title": "Files with Suspicious Names",
      "category": "Security Risk",
      "purpose": "Locates files with names suggesting they may contain passwords, credentials, or other sensitive information.",
      "query": "SELECT \n  parentPath as \"Path\",\n  name as \"File Name\", \n  osOwner as \"Owner\",\n modifyTime as \"Last Modified\"\nWHERE \n  ((name LIKE '%password%'\n   OR name LIKE '%passwd%'\n   OR name LIKE '%credential%'\n   OR name LIKE '%secret%'\n   OR name LIKE '%.key%'\n   OR name LIKE '%apikey%'\n   OR name LIKE '%api_key%'\n   OR name LIKE '%token%')\n  AND ClassID = 'idxobject')\nORDER BY \n  \"Last Modified\" DESC;",
      "impact": "Hard-coded credentials in plain text files are a leading cause of security breaches, with the average breach costing $4.35 million. This query helps identify potentially exposed credentials before they can be exploited. Security teams can remediate these issues proactively, saving an average of $1.2 million per avoided breach. Employees benefit from improved security practices without productivity loss.",
      "action": "Inspect these files to ensure sensitive information isn't inappropriately stored.",
      "verified": true,
      "visualization": false,
      "keywords": [
        "password",
        "key",
        "api",
        "token",
        "credentials"
      ],
      "modified": "2025-04-11T15:50:20.471577"
    },
    {
      "id": "public_permission_files",
      "title": "Find Files with Public Access",
      "category": "Security Risk",
      "purpose": "Discovers files with overly permissive access settings that could lead to unauthorized access.",
      "query": "SELECT \n  parentPath as \"Path\",\n  name as \"File Name\", \n  service as \"Service\",\n  osPermission as \"Permissions\",\n  osOwner as \"Owner\"\nWHERE \n  --(osPermission LIKE '%PUBLIC%' \n  -- OR osPermission LIKE '%EVERYONE%'\n   --OR osPermission = '777'\n  -- OR osPermission LIKE '%Full Control%') AND \nClassID = 'idxobject'\nORDER BY \n  service, parentPath;",
      "impact": "Overly permissive files create significant security vulnerabilities - 63% of data breaches involve access control issues. This query identifies permission problems before they can be exploited. Organizations implementing proper access controls based on these findings see unauthorized access attempts drop by 30-45%. Department managers gain confidence that their sensitive data is properly protected, while IT avoids emergency remediations.",
      "action": "Review and adjust permissions to follow principle of least privilege.",
      "verified": true,
      "visualization": false,
      "notes": "Permissions is OWNER really",
      "keywords": [
        "file permissions", "access control issues", "overly permissive files", "unauthorized access prevention", "least privilege principle", "loose permissions", "public access risk", "secure file permissions", "access settings audit"
      ],
      "modified": "2025-04-11T15:56:57.290394"
    },
    {
      "id": "keys_and_certificates_exposure",
      "title": "Keys and Certificates Exposure",
      "category": "Security Risk",
      "purpose": "Finds files likely to contain cryptographic keys, certificates, or credentials that should be secured.",
      "query": "SELECT \n  parentPath as \"Path\",\n  name as \"File Name\", \n  extension as \"Extension\",\n  size as \"Size (Bytes)\",\n  CONCAT(YEAR(modifyTime), '-', MONTH(modifyTime), '-', DAY(modifyTime)) as \"Last Modified\"\nWHERE \n  ((extension IN ('pem','key','ppk','pfx','p12','cer','crt','keystore','jks') \n   OR name LIKE '%id_rsa%' \n   OR name LIKE '%id_dsa%'\n   OR name LIKE '%private%key%'\n   OR name LIKE '%ssl%key%')\n  AND ClassID = 'idxobject')\nORDER BY \n  \"Last Modified\" DESC;",
      "impact": "Exposed cryptographic materials can lead to devastating breaches - compromised keys were involved in 43% of major breaches last year. This query helps locate and secure keys and certificates before compromise. Organizations that implement proper key management reduce crypto-related security incidents by 75-90%. For developers and operations teams, this prevents the frantic rotation of compromised credentials that often leads to production outages.",
      "action": "Ensure keys and certificates are properly secured and not exposed in inappropriate locations.",
      "verified": true,
      "keywords": [
        "Cryptographic Keys",
        "Certificates",
        "Credentials Security",
        "Key Management",
        "Data Breaches",
        "Compromised Keys",
        "Cybersecurity",
        "Security Best Practices",
        "System Vulnerabilities",
        "Unauthorized Access",
        "Key Rotation",
        "Sensitive Data"
      ],
      "visualization": false
    },
    {
      "id": "environment_and_configuration_files",
      "title": "Environment and Configuration Files",
      "category": "Security Risk",
      "purpose": "Identifies configuration files that may contain sensitive connection strings, API keys, or other secrets.",
      "query": "SELECT \n  parentPath as \"Path\",\n  name as \"File Name\", \n  extension as \"Extension\",\n  osOwner as \"Owner\",\n  modifyTime as\"Last Modified\"\nWHERE \n  (name LIKE '%.env%' \n   OR name LIKE '%config%' \n   OR name LIKE '%setting%'\n   OR extension IN ('ini','conf','cfg','config','yml','yaml','properties'))\n  AND ClassID = 'idxobject'\nORDER BY \n  modifyTime DESC;",
      "impact": "Configuration files with hardcoded secrets represent one of the most common security vulnerabilities in corporate environments. This query helps identify these risks before attackers do, reducing the average detection time for credential exposures from 280 days to less than 30. Development teams spend 30-40% less time on emergency credential rotations, allowing more focus on feature development instead of security firefighting.",
      "action": "Review configuration files for hardcoded credentials or secrets.",
      "verified": true,
      "visualization": false,
      "keywords": [
        "Configuration Files",
        "Sensitive Data",
        "Connection Strings",
        "API Keys",
        "Hardcoded Secrets",
        "Credential Exposures",
        "Security Vulnerabilities",
        "Emergency Rotations",
        "Feature Development",
        "Security Firefighting",
        "Secret Management",
        "Data Protection",
        "Risk Mitigation"
      ],
      "modified": "2025-04-11T16:14:44.031557"
    },
    {
      "id": "non_business_media_files",
      "title": "Find Personal Media Files",
      "category": "Security Risk",
      "purpose": "Locates personal media files that may violate acceptable use policies or consume inappropriate amounts of storage.",
      "query": "SELECT \n  parentPath as \"Path\",\n  name as \"File Name\", \n  extension as \"Extension\",\n  size as \"Size (Bytes)\",\n  size/1048576 as \"Size (MB)\",\n  osOwner as \"Owner\"\nWHERE \n  extension IN ('mp3','mp4','avi','mov','mkv','flv','wav','aac','ogg','jpg','jpeg','png','gif','bmp','tiff')\n  AND size > 10485760 -- Greater than 10MB\n  AND ClassID ='idxobject'\nORDER BY \n  size DESC;",
      "impact": "Non-business media files often consume 15-25% of corporate storage while increasing legal and security risks. This query helps identify policy violations and reduce unnecessary storage costs. Organizations that implement this analysis typically recover 10-20% of their storage capacity while reducing exposure to copyright infringement claims. Employees benefit from clearer guidance on acceptable use policies and faster network performance.",
      "action": "Review large media files for compliance with acceptable use policies.",
      "verified": true,
      "visualization": false,
      "keywords": [
        "Personal Media Files",
        "Acceptable Use Policies",
        "Storage Consumption",
        "Non-business Media",
        "Legal Risks",
        "Security Risks",
        "Copyright Infringement",
        "Storage Costs",
        "Corporate Storage",
        "File System Query",
        "Policy Violations",
        "Media File Audit",
        "Data Optimization",
        "Storage Recovery",
        "Network Performance",
        "Large File Analysis",
        "Compliance Review"
      ],
      "modified": "2025-04-11T16:19:50.937513"
    },
    {
      "id": "database_and_backup_files",
      "title": "Database and Backup Files",
      "category": "Security Risk",
      "purpose": "Finds database files and backups that may contain sensitive information but lack proper protection.",
      "query": "SELECT \n  parentPath as \"Path\",\n  name as \"File Name\", \n  extension as \"Extension\",\n  size as \"Size (Bytes)\",\n  size/1048576 as \"Size (MB)\",\n  CONCAT(YEAR(modifyTime), '-', MONTH(modifyTime), '-', DAY(modifyTime)) as \"Last Modified\"\nWHERE \n  (extension IN ('db','sqlite','sqlite3','mdb','accdb','bak','backup','sql','dump','vbk','vbr','vib') \n   OR name LIKE '%database%'\n   OR name LIKE '%backup%')\n  -- Note: LIKE is case-insensitive in AQL\n  AND ClassID = 'idxobject'\nORDER BY \n  size DESC;",
      "impact": "Unsecured database files and backups are involved in 34% of data breaches, often exposing thousands of records in a single incident. This query helps ensure database assets are properly protected, potentially preventing incidents that cost an average of $180 per compromised record. Database administrators spend less time tracking down rogue database files, while compliance officers can document proper controls for sensitive data repositories.",
      "action": "Ensure database files and backups are properly secured and not stored in inappropriate locations.",
      "keywords": [
        "Database Files",
        "Backups",
        "Sensitive Information",
        "Unsecured Data",
        "Data Breaches",
        "Security Vulnerabilities",
        "Data Protection",
        "Database Security",
        "Backup Storage",
        "Sensitive Records",
        "Data Repository",
        "Risk Mitigation",
        "Compliance Documentation",
        "Cost Prevention",
        "Database Administrators",
        "Rogue Files",
        "Corporate Security"
      ],
      "verified": true,
      "visualization": false
    },
    {
      "id": "recently_modified_executables",
      "title": "Recently Modified Executables",
      "category": "Security Risk",
      "purpose": "Identifies executable files that have been modified recently, which could indicate malicious activity or unauthorized software installation.",
      "query": "-- Query uses date template variables which will be automatically replaced with actual dates\n-- based on the current date when the query is executed.\n-- As of today (2025-03-25), {{DATE_MINUS_30_DAYS}} = 2025-02-23\nSELECT \n  parentPath as \"Path\",\n  name as \"File Name\", \n  extension as \"Extension\",\n  CONCAT(YEAR(modifyTime), '-', MONTH(modifyTime), '-', DAY(modifyTime)) as \"Last Modified\",\n  osOwner as \"Owner\"\nWHERE \n  extension IN ('exe','dll','so','bin','sh','bat')\n  AND modifyTime >= '{{DATE_MINUS_30_DAYS}}' -- Look for executables modified in the last 30 days\n  AND ClassID = 'idxobject'\nORDER BY \n  modifyTime DESC;",
      "impact": "Recently modified executables are often early indicators of compromise, as attackers replace legitimate system files with malicious versions. This query helps security teams detect potential intrusions within days rather than the industry average of 207 days. Organizations implementing this monitoring can reduce the cost of a breach by 30-40% through early detection. End users experience fewer compromised systems and less downtime from security incidents.",
      "action": "Verify that recent executable modifications are authorized and legitimate.",
      "verified": true,
      "keywords": [
        "Recently Modified Executables",
        "Malicious Activity",
        "Unauthorized Software",
        "System Files",
        "Compromise Detection",
        "Early Detection",
        "Cost Reduction",
        "Security Breaches",
        "Downtime",
        "End Users",
        "Compromise Prevention",
        "System Security",
        "File System Query",
        "Executable Analysis",
        "Security Monitoring",
        "Cost Savings",
        "Risk Mitigation",
        "Corporate Security",
        "Executable Analysis",
        "Security Monitoring",
        "Cost Savings",
        "Risk Mitigation",
        "Corporate Security"
      ],
      "visualization": false
    },
    {
      "id": "sensitive_data_inventory",
      "title": "Locate All Sensitive Data",
      "category": "Privacy Compliance",
      "purpose": "Creates a comprehensive inventory of files containing personally identifiable information (PII) or other sensitive data.",
      "query": "  -- Only selecting one classification field to avoid duplicates\nSELECT \n  parentPath as \"Path\",\n  name as \"File Name\", \n  classification as \"Classification\",\n  confidence as \"Confidence Score\",\n  osOwner as \"Owner\",\n  createTime as \"Created\",\n  modifyTime as \"Last Modified\"\nWHERE \n  (-- GDPR and Country-Specific Data Protection\n   classification LIKE '%GDPR%'\n   OR classification LIKE '%Personal Data Policy%'\n   \n   -- Health Information\n   OR classification LIKE '%PHI%'\n   OR classification LIKE '%HIPAA%'\n   \n   -- Sensitive data categories\n   OR classification LIKE '%Sensitive Data Policy%'\n   \n   -- National ID documents\n   OR classification LIKE '%National ID%'\n   OR classification LIKE '%Passport%'\n   OR classification LIKE '%Drivers License%'\n   OR classification LIKE '%Tax Reference%'\n   \n   -- PII general\n   OR classification LIKE '%PII%')\n  AND ClassID = 'idxobject'\nORDER BY \n  confidence DESC,\n  modifyTime DESC;",
      "impact": "Unidentified sensitive data is the root cause of 82% of compliance violations. This query provides the foundation for effective governance, enabling targeted protection rather than broad restrictions. Organizations using sensitive data inventories typically reduce compliance audit findings by 65-75% while cutting assessment time by 40-50%. For privacy officers, this inventory enables accurate Data Protection Impact Assessments (DPIAs) with significantly less manual effort.",
      "action": "Ensure all sensitive data is properly protected according to classification.",
      "verified": true,
      "keywords": [
        "Sensitive Data Inventory",
        "PII",
        "GDPR",
        "Personal Data Policy",
        "PHI",
        "HIPAA",
        "Sensitive Data Policy",
        "National ID",
        "Passport",
        "Drivers License",
        "Tax Reference"
      ],
      "visualization": false
    },
    {
      "id": "high_confidence_pii_detection",
      "title": "High-Confidence PII Detection",
      "category": "Privacy Compliance",
      "purpose": "Identifies files containing PII with high confidence scores to prioritize protection for the most sensitive data.",
      "query": "-- Using a focused approach with just the primary classification field\nSELECT \n  parentPath as \"Path\",\n  name as \"File Name\", \n  classification as \"Classification\",\n  confidence as \"Confidence Score\",\n  osOwner as \"Owner\",\n  size/1048576 as \"Size (MB)\",\n  CONCAT(YEAR(createTime), '-', MONTH(createTime), '-', DAY(createTime)) as \"Creation Date\",\n  CONCAT(YEAR(modifyTime), '-', MONTH(modifyTime), '-', DAY(modifyTime)) as \"Last Modified Date\"\nWHERE \n  (-- Country-specific personal data policies\n   classification LIKE '%United States Personal Data Policy%'\n   OR classification LIKE '%Canada Personal Data Policy%'\n   OR classification LIKE '%EU General Data Protection Regulation (GDPR)%'\n   OR classification LIKE '%United Kingdom Personal Data Policy%'\n   \n   -- Financial and banking information\n   OR classification LIKE '%Bank Account Number Policy%'\n   OR classification LIKE '%Credit/Bank Card Policy%'\n   OR classification LIKE '%PCI-DSS Policy%'\n   \n   -- Healthcare-related classifications\n   OR classification LIKE '%PHI%'\n   OR classification LIKE '%HIPAA%'\n   \n   -- National IDs and Documents\n   OR classification LIKE '%National ID Policy%'\n   OR classification LIKE '%Passport Policy%'\n   OR classification LIKE '%Drivers License Number Policy%')\n   \n  -- Only include classifications with very high confidence (90 or higher)\n  AND confidence >= 90\n  AND ClassID = 'idxobject'\nORDER BY \n  confidence DESC,\n  size DESC;",
      "impact": "Focusing on high-confidence PII dramatically improves protection effectiveness. Organizations report reducing false positives by 50-70% and cutting investigation time by 35-45% when prioritizing by confidence score. Privacy teams can allocate resources to the most critical data first, while delivering quantifiable risk reduction metrics to executives and regulators. This approach enables an 80/20 strategy that protects the most sensitive data quickly while methodically addressing lower confidence findings over time.",
      "action": "Immediately review and apply enhanced protection to high-confidence PII findings, especially larger files that may contain bulk sensitive data.",
      "verified": true,
      "keywords": [
        "Sensitive Data Inventory",
        "PII",
        "GDPR",
        "Personal Data Policy",
        "PHI",
        "HIPAA",
        "Sensitive Data Policy",
        "National ID",
        "Passport",
        "Drivers License",
        "Tax Reference"
      ],
      "visualization": false
    },
    {
      "id": "sensitive_data_by_storage_location",
      "title": "Where Is Sensitive Data Stored",
      "category": "Privacy Compliance",
      "purpose": "Maps where sensitive data resides across different storage sources to understand compliance risk distribution.",
      "query": "-- Summarizing sensitive data by location using only classification field\nSELECT \n  parentPath as \"Storage Location\",\n  COUNT(*) as \"Total Files\",\n  SUM(size)/1048576 as \"Total Size (MB)\",\n  AVG(confidence) as \"Average Confidence Score\"\nWHERE \n  classification IS NOT NULL\n  AND classification != ''\n  AND (\n    -- Privacy regulations\n    classification LIKE '%GDPR%'\n    OR classification LIKE '%Personal Data Policy%'\n    OR classification LIKE '%PHI%'\n    OR classification LIKE '%HIPAA%'\n    OR classification LIKE '%Sensitive Data Policy%'\n    \n    -- Financial data\n    OR classification LIKE '%PCI-DSS%'\n    OR classification LIKE '%Credit/Bank Card Policy%'\n    OR classification LIKE '%Bank Account Number Policy%'\n    \n    -- National IDs\n    OR classification LIKE '%National ID%'\n    OR classification LIKE '%Passport%'\n    OR classification LIKE '%Drivers License%'\n  )\n  AND ClassID = 'idxobject'\nGROUP BY \n  parentPath\nORDER BY \n  \"Total Files\" DESC;",
      "impact": "Understanding where sensitive data concentrates allows for prioritized security investments. Organizations can achieve the same protection outcomes while reducing security spending by 20-30% through this focused approach. IT teams can implement appropriate security controls where they matter most, while business units gain transparency into their data risk profile, allowing better risk management decisions.",
      "action": "Identify repositories with high concentrations of sensitive data for targeted protection.",
      "verified": true,
      "keywords": [
        "Sensitive Data Inventory",
        "PII",
        "GDPR",
        "Personal Data Policy",
        "PHI",
        "HIPAA",
        "Sensitive Data Policy",
        "National ID",
        "Passport",
        "Drivers License",
        "Tax Reference"
      ],
      "visualization": false
    },
    {
      "id": "expired_retention_data",
      "title": "Expired Retention Data",
      "category": "Privacy Compliance",
      "purpose": "Identifies data that has exceeded its allowed retention period according to your policies.",
      "query": "-- Query uses date template variables which will be automatically replaced with actual dates\n-- based on the current date when the query is executed.\n-- As of today (2025-03-25):\n--   {{DATE_MINUS_2_YEARS}} = 2023-03-25 (for PII data)\n--   {{DATE_MINUS_5_YEARS}} = 2020-03-25 (for general classified data)\n--   {{DATE_MINUS_7_YEARS}} = 2018-03-25 (for financial data)\n--   {{DATE_MINUS_10_YEARS}} = 2015-03-25 (for legal data)\nSELECT \n  parentPath as \"Path\",\n  name as \"File Name\", \n  classification as \"Classification\",\n  createTime as \"Creation Date\",\n  modifyTime as \"Last Modified\"\nWHERE \n  (\n    (classification LIKE '%PII%' AND createTime < '{{DATE_MINUS_2_YEARS}}') -- PII older than 2 years\n    OR \n    (classification LIKE '%Financial%' AND createTime < '{{DATE_MINUS_7_YEARS}}') -- Financial older than 7 years\n    OR\n    (classification LIKE '%Legal%' AND createTime < '{{DATE_MINUS_10_YEARS}}') -- Legal older than 10 years\n    OR\n    (classification IS NOT NULL AND classification != '' AND createTime < '{{DATE_MINUS_5_YEARS}}') -- Other classified data older than 5 years\n  )\n  AND (ClassID = 'idxobject')\nORDER BY \n  \"Creation Date\" ASC;",
      "impact": "Retention violations can result in significant regulatory penalties - up to 4% of global revenue under some regulations. This query automatically identifies expired data, reducing violations by 70-80%. Legal teams gain confidence in retention compliance, while IT teams can automate cleanup processes. For end users, this prevents accidental use of outdated information that could lead to business errors or compliance issues.",
      "action": "Review expired data for defensible deletion or archive to offline storage.",
      "verified": true,
      "keywords": [
        "Sensitive Data Inventory",
        "Expired Data",
        "Data Retention Policies",
        "PII",
        "GDPR",
        "Personal Data Policy",
        "PHI",
        "HIPAA",
        "Sensitive Data Policy",
        "National ID",
        "Passport",
        "Drivers License",
        "Tax Reference"
      ],
      "visualization": false
    },
    {
      "id": "stale_sensitive_data",
      "title": "Stale Sensitive Data",
      "category": "Privacy Compliance",
      "purpose": "Locates sensitive data that hasn't been modified in a long time but is still in active storage.",
      "query": "-- Query uses date template variables which will be automatically replaced with actual dates\n-- based on the current date when the query is executed.\n-- As of today (2025-03-25), {{DATE_MINUS_1_YEAR}} = 2024-03-25\nSELECT \n  parentPath as \"Path\",\n  name as \"File Name\", \n  classification as \"Classification\",\n  modifyTime as \"Last Modified\",\n  osOwner as \"Owner\"\nWHERE \n  (classification IS NOT NULL)\n  AND (classification != '')\n  AND (modifyTime < '{{DATE_MINUS_1_YEAR}}') -- Data older than 1 year\n  AND (ClassID = 'idxobject')\nORDER BY \n  \"Last Modified\" ASC;",
      "impact": "Active storage of stale sensitive data increases both security risk and storage costs. Moving this data to secure archives typically reduces storage costs by 60-80% while improving security posture. Legal and compliance teams benefit from knowing sensitive data is properly controlled throughout its lifecycle, while reducing the scope of potential breaches. Users searching for current information find results faster when stale data is archived.",
      "action": "Consider moving stale sensitive data to secure archive storage.",
      "verified": true,
      "keywords": [
        "Sensitive Data",
        "Stale Data",
        "Active Storage",
        "Data Archiving",
        "Data Classification",
        "Security Risks",
        "Storage Costs",
        "Compliance Teams",
        "Legal Teams",
        "Data Lifecycle",
        "Secure Archives",
        "Risk Mitigation",
        "Data Breaches",
        "Storage Optimization",
        "System Performance",
        "Sensitive Information",
        "Data Retention Policies",
        "Efficient Data Management"
      ],
      "visualization": false
    },
    {
      "id": "personally_identifiable_information_pii_risk_assessment",
      "title": "PII Risk Assessment",
      "category": "Privacy Compliance",
      "purpose": "Provides a risk analysis of PII data by combining classification, location, and access information.",
      "query": "SELECT \n  parentPath as \"Path\",\n  name as \"File Name\", \n  classification as \"Classification\",\n  osPermission as \"Permissions\",\n  osOwner as \"Owner\",\n  CASE\n    WHEN osPermission LIKE '%PUBLIC%' OR osPermission LIKE '%EVERYONE%' OR osPermission = '777' THEN 'High Risk'\n    WHEN osPermission LIKE '%GROUP%' OR osPermission LIKE '%650%' OR osPermission LIKE '%660%' THEN 'Medium Risk'\n    ELSE 'Standard Risk'\n  END as \"Risk Level\"\nWHERE \n  (classification LIKE '%PII%' OR classification LIKE '%Personal%')\n  AND ClassID = 'idxobject'\nORDER BY \n\"Risk Level\";",
      "impact": "PII breaches cost organizations an average of $150-200 per record exposed. This risk-based approach helps security teams focus on the most critical issues first, typically reducing data breach likelihood by 45-60%. For compliance and privacy officers, this provides documentation of risk-based controls as required by many regulations. End users maintain appropriate access to necessary files while high-risk cases are remediated.",
      "action": "Address high-risk files first by restricting permissions or relocating files.",
      "verified": true,
      "visualization": false,
      "keywords": [
        "PII Data",
        "Risk Analysis",
        "Classification",
        "Data Location",
        "Access Information",
        "Sensitive Data",
        "High Risk Files",
        "Medium Risk Files",
        "Standard Risk Files",
        "Permissions Management",
        "Compliance Requirements",
        "Privacy Regulations",
        "Data Breaches",
        "Security Teams",
        "Risk Mitigation",
        "Data Protection",
        "Sensitive Information",
        "Remediation Priorities"
      ],
      "modified": "2025-04-13T10:47:54.606431"
    },
    {
      "id": "cross_border_data_analysis",
      "title": "Cross-Border Data Analysis",
      "category": "Privacy Compliance",
      "purpose": "Helps identify data residing in locations that may trigger cross-border data transfer concerns.",
      "query": "SELECT \n  parentPath as \"Storage Source\",\n  geographical-location as \"Geographic Location\",\n  classification as \"Classification\",\n  COUNT(name) as \"File Count\"\nWHERE \n  classification IS NOT NULL\n  AND classification != ''\n  AND geographical-location IS NOT NULL\n  AND ClassID = 'idxobject'\nGROUP BY \n  parentPath, geographical-location, classification\nORDER BY \n  geographical-location, COUNT(name) DESC;",
      "impact": "Cross-border data transfers that violate regulations like GDPR can result in fines up to \u20ac20 million or 4% of global revenue. This analysis helps identify and remediate non-compliant transfers before regulators do, saving millions in potential penalties. Legal teams can document compliance with international data transfer requirements, while business operations continue without disruption from regulatory enforcement actions.",
      "action": "Review data location against compliance requirements for cross-border transfers.",
      "verified": true,
      "visualization": false,
      "keywords": [
        "Cross-Border Data",
        "Data Transfer",
        "GDPR",
        "Compliance",
        "Geographic Location",
        "Classification",
        "File Count",
        "Storage Source",
        "Data Transfer",
        "GDPR",
        "Compliance",
        "Geographic Location",
        "Classification",
        "File Count",
        "Storage Source"
      ],
      "modified": "2025-04-13T10:47:54.606431"
    },
    {
      "id": "third_party_access_to_sensitive_data",
      "title": "Third-Party Access to Sensitive Data",
      "category": "Privacy Compliance",
      "purpose": "Identifies sensitive data accessible by external users or systems.",
      "query": "SELECT \n  parentPath as \"Path\",\n  name as \"File Name\", \n  classification as \"Classification\",\n  osOwner as \"Owner\",\n  osPermission as \"Permissions\"\nWHERE \n  classification IS NOT NULL\n  AND classification != ''\n  AND (\n    osPermission LIKE '%External%' \n    OR osPermission LIKE '%Partner%'\n    OR osPermission LIKE '%Vendor%'\n    OR osPermission LIKE '%Contractor%'\n  )\n  AND ClassID = 'idxobject'\nORDER BY \n  classification;",
      "impact": "Third-party access is involved in 51-74% of data breaches, with each breach costing an average of $4.35 million. This query helps identify potential third-party risks for remediation. Vendor management teams can verify that access aligns with contractual terms, reducing improper access by 50-60%. Business relationships continue smoothly while ensuring appropriate data protections are in place.",
      "action": "Review all cases of third-party access to sensitive data for contractual compliance.",
      "verified": true,
      "visualization": false,
      "keywords": [
        "Sensitive Data",
        "External Access",
        "Third-party Risks",
        "Vendor Access",
        "Partner Access",
        "Contractor Access",
        "Data Classification",
        "Permissions Management",
        "Access Compliance",
        "Contractual Terms",
        "Risk Analysis",
        "Data Breaches",
        "Security Vulnerabilities",
        "Remediation Process",
        "Sensitive Information",
        "Vendor Management",
        "Data Protections",
        "Corporate Security"
      ],
      "modified": "2025-04-13T10:47:54.606431"
    },
    {
      "id": "credit_card_data_detection",
      "title": "Find Credit Card Numbers",
      "category": "Privacy Compliance",
      "purpose": "Helps locate potential credit card numbers that may be subject to PCI DSS requirements.",
      "query": "SELECT \n  parentPath as \"Path\",\n  name as \"File Name\", \n  classification as \"Classification\",\n  extension as \"File Type\"\nWHERE \n  (\n    classification LIKE '%PCI%'\n    OR classification LIKE '%Credit Card%'\n    OR name LIKE '%credit%card%'\n    OR name LIKE '%payment%'\n  )\n  AND ClassID = 'idxobject'\nORDER BY \n  extension, name;",
      "impact": "PCI DSS violations can result in fines of $5,000 to $100,000 per month until remediated, plus reputational damage from breaches. This query helps identify potential PCI scope for proper protection, typically reducing the scope of PCI audits by 30-50%. This translates to significant audit cost savings while maintaining payment processing capabilities. Finance teams gain confidence that payment data is properly secured.",
      "action": "Verify and secure any files that may contain payment card information.",
      "verified": true,
      "visualization": false,
      "keywords": [
        "PCI DSS",
        "Credit Card Data",
        "Sensitive Information",
        "Payment Card Data",
        "Data Security",
        "Compliance Violations",
        "Reputational Damage",
        "Audit Scope Reduction",
        "Payment Processing",
        "Finance Teams",
        "Cost Savings",
        "Data Protection",
        "Query Analysis",
        "Corporate Compliance",
        "Sensitive File Verification",
        "Risk Mitigation",
        "Security Best Practices",
        "Payment Information"
      ],
      "modified": "2025-04-13T10:47:54.606431"
    },
    {
      "id": "healthcare_data_phi_analysis",
      "title": "Healthcare Data (PHI) Analysis",
      "category": "Privacy Compliance",
      "purpose": "Specifically targets potential Protected Health Information (PHI) subject to HIPAA regulations.",
      "query": "SELECT \n  parentPath as \"Path\",\n  name as \"File Name\", \n  classification as \"Classification\",\n  osOwner as \"Owner\"\nWHERE \n  (\n    classification LIKE '%PHI%'\n    OR classification LIKE '%HIPAA%'\n    OR classification LIKE '%Health%'\n    OR classification LIKE '%Medical%'\n    OR name LIKE '%patient%'\n    OR name LIKE '%medical%'\n    OR name LIKE '%health%'\n  )\n  AND ClassID = 'idxobject'\nORDER BY \n  parentPath, name;",
      "impact": "HIPAA violations can cost up to $1.5 million per year, with potential criminal penalties for willful neglect. This query helps ensure PHI is properly identified and protected, typically reducing compliance gaps by 70-85%. Healthcare providers and business associates demonstrate due diligence in protecting patient information, while IT teams can apply appropriate technical safeguards to the correct data sets.",
      "action": "Ensure all PHI is properly secured and access-controlled according to HIPAA requirements.",
      "verified": true,
      "visualization": false,
      "keywords": [
        "Protected Health Information",
        "PHI",
        "HIPAA Compliance",
        "Sensitive Data",
        "Patient Information",
        "Medical Records",
        "Healthcare Providers",
        "Business Associates",
        "Data Classification",
        "Technical Safeguards",
        "Compliance Gaps",
        "Risk Mitigation",
        "Security Best Practices",
        "Access Controls",
        "Data Breaches",
        "Regulatory Penalties",
        "Secure Archives",
        "Information Protection"
      ],
      "modified": "2025-04-13T10:47:54.606431"
    },
    {
      "id": "classification_coverage_assessment",
      "title": "Classification Coverage Assessment",
      "category": "Governance Lifecycle",
      "purpose": "Provides a high-level view of how much data is properly classified vs. unclassified across the enterprise.",
      "query": "SELECT \n  CASE \n    WHEN classification IS NULL THEN 'Unclassified'\n    WHEN classification = '' THEN 'Unclassified'\n    WHEN classification LIKE '%unclassified%' THEN 'Unclassified'\n    ELSE 'Classified'\n  END as \"Classification Status\",\n  COUNT(name) as \"File Count\",\n  SUM(size) as \"Total Size (Bytes)\",\n  SUM(size)/1048576 as \"Total Size (MB)\"\nWHERE \n  ClassID = 'idxobject'\nGROUP BY \n  CASE \n    WHEN classification IS NULL THEN 'Unclassified'\n    WHEN classification = '' THEN 'Unclassified'\n    WHEN classification LIKE '%unclassified%' THEN 'Unclassified'\n    ELSE 'Classified'\n  END;",
      "impact": "Without classification, organizations struggle to implement effective governance and protection. This query provides executives with a dashboard-level view of classification maturity. Organizations with high classification coverage (>70%) typically reduce data incidents by 45-60% compared to those with poor coverage (<30%). Data stakeholders throughout the organization benefit from improved data findability and appropriate protection, while IT governance teams can target resources where they are most needed.",
      "action": "Target unclassified data for classification initiatives.",
      "verified": true,
      "visualization": false,
      "keywords": [
        "Data Classification",
        "Unclassified Data",
        "Governance Challenges",
        "Classification Maturity",
        "Dashboard-Level View",
        "Data Coverage",
        "Classification Initiatives",
        "Data Incidents",
        "Data Findability",
        "IT Governance",
        "Data Protection",
        "Enterprise Data",
        "Sensitive Information",
        "Resource Allocation",
        "Data Management",
        "Corporate Security",
        "Classification Analysis",
        "Improved Protection"
      ],
      "modified": "2025-04-13T11:35:19.279951"
    },
    {
      "id": "classification_coverage_by_storage_source",
      "title": "Data Classification Coverage",
      "category": "Governance Lifecycle",
      "purpose": "Breaks down classification coverage by storage source to identify problem areas.",
      "query": "-- Classification Coverage by Storage Source\n-- This query breaks down classification coverage by storage source to identify problem areas\n\n\n-- Simplified approach that avoids complex calculations\nSELECT \n  parentPath as \"Storage Source\",\n  CASE \n    WHEN classification IS NULL THEN 'Unclassified'\n    WHEN classification = '' THEN 'Unclassified'\n    WHEN classification LIKE '%unclassified%' THEN 'Unclassified'\n    ELSE 'Classified'\n  END as \"Classification Status\",\n  COUNT(*) as \"File Count\"\nFROM idxobject\nWHERE \n  ClassID = 'idxobject'\nGROUP BY \n  parentPath,\n  CASE \n    WHEN classification IS NULL THEN 'Unclassified'\n    WHEN classification = '' THEN 'Unclassified'\n    WHEN classification LIKE '%unclassified%' THEN 'Unclassified'\n    ELSE 'Classified'\n  END\nORDER BY \n  parentPath ,\n  \"Classification Status\";\n\n-- Note: For percentages, run this query first to get total counts by service:\n-- SELECT service, COUNT(*) as \"Total Files\" FROM idxobject \n-- WHERE ClassID = 'idxobject' GROUP BY service;",
      "impact": "Storage source-level analysis enables targeted governance investments where they will have the greatest impact. Organizations implementing focused classification initiatives based on this analysis typically improve overall classification rates 3x faster than with undirected approaches. Storage administrators benefit from clear prioritization guidance, while governance leaders can allocate resources efficiently to maximize ROI on classification efforts.",
      "action": "Focus classification efforts on sources with low coverage rates.",
      "verified": true,
      "visualization": false,
      "keywords": [
        "Classification Coverage",
        "Storage Source Analysis",
        "Unclassified Data",
        "Classified Data",
        "Governance Investments",
        "Data Classification",
        "Prioritization Guidance",
        "ROI Maximization",
        "Targeted Initiatives",
        "Storage Administrators",
        "Governance Leaders",
        "Classification Rates",
        "Resource Allocation",
        "Data Management",
        "Corporate Security",
        "System Optimization",
        "Problem Areas",
        "Data Insights"
      ],
      "modified": "2025-04-13T11:08:15.369257"
    },
    {
      "id": "orphaned_files_analysis",
      "title": "Orphaned Files Analysis",
      "category": "Governance Lifecycle",
      "purpose": "Identifies files with no clear owner that may require ownership assignment.",
      "query": "SELECT \n  parentPath as \"Path\",\n  name as \"File Name\", \n  size as \"Size (Bytes)\",\n  modifyTime as \"Last Modified\",\n  CASE\n    WHEN osOwner IS NULL THEN 'Missing Owner'\n    WHEN osOwner = '' THEN 'Empty Owner'\n    ELSE osOwner\n  END as \"Owner Status\"\nWHERE \n  (osOwner IS NULL OR osOwner = '')\n  AND ClassID = 'idxobject'\nORDER BY \n  modifyTime DESC,\n  size DESC;",
      "impact": "Orphaned files create significant governance risks - when ownership is unclear, proper lifecycle management fails. This query typically identifies 15-25% of enterprise files that lack proper ownership. IT departments can reduce rogue data sprawl by 30-45% through ownership assignment campaigns. Department managers gain visibility into unmanaged assets, while legal teams can ensure retention policies apply to all data, not just obviously owned content.",
      "action": "Assign owners to orphaned files, especially for recent or large files.",
      "keywords": [
        "Orphaned Files",
        "Ownership Assignment",
        "Unmanaged Assets",
        "Governance Risks",
        "Lifecycle Management",
        "Retention Policies",
        "Data Visibility",
        "Rogue Data Sprawl",
        "Legal Compliance",
        "IT Departments",
        "Ownership Campaigns",
        "File Management",
        "Enterprise Files",
        "Data Protection",
        "Sensitive Data",
        "Corporate Governance",
        "Data Classification",
        "Large Files"
      ],
      "verified": true,
      "visualization": false
    },
    {
      "id": "data_lifecycle_stage_analysis",
      "title": "Data Lifecycle Stages",
      "category": "Governance Lifecycle",
      "purpose": "Categorizes data into lifecycle stages based on age and recent activity.",
      "query": "-- Query uses date template variables which will be automatically replaced with actual dates\n-- based on the current date when the query is executed.\n-- As of today (2025-03-25):\n--   {{DATE_MINUS_90_DAYS}} = 2024-12-25 (for new data)\n--   {{DATE_MINUS_6_MONTHS}} = 2024-09-25 (for active data)\n--   {{DATE_MINUS_1_YEAR}} = 2024-03-25 (for aging data)\n--   {{DATE_MINUS_3_YEARS}} = 2022-03-25 (for inactive data)\nSELECT \n  CASE \n    WHEN createTime >= '{{DATE_MINUS_90_DAYS}}' THEN 'New (0-90 days)'\n    WHEN modifyTime >= '{{DATE_MINUS_6_MONTHS}}' THEN 'Active (Modified <6 months)'\n    WHEN modifyTime >= '{{DATE_MINUS_1_YEAR}}' THEN 'Aging (Modified 6-12 months)'\n    WHEN modifyTime >= '{{DATE_MINUS_3_YEARS}}' THEN 'Inactive (Modified 1-3 years)'\n    ELSE 'Archival (Modified >3 years)'\n  END as \"Lifecycle Stage\",\n  COUNT(name) as \"File Count\",\n  SUM(size) as \"Total Size (Bytes)\",\n  SUM(size)/1048576 as \"Total Size (MB)\"\nWHERE \n  (ClassID = 'idxobject')\nGROUP BY \n  CASE \n    WHEN createTime >= '{{DATE_MINUS_90_DAYS}}' THEN 'New (0-90 days)'\n    WHEN modifyTime >= '{{DATE_MINUS_6_MONTHS}}' THEN 'Active (Modified <6 months)'\n    WHEN modifyTime >= '{{DATE_MINUS_1_YEAR}}' THEN 'Aging (Modified 6-12 months)'\n    WHEN modifyTime >= '{{DATE_MINUS_3_YEARS}}' THEN 'Inactive (Modified 1-3 years)'\n    ELSE 'Archival (Modified >3 years)'\n  END",
      "impact": "Lifecycle-aware data management can reduce storage costs by 25-40% while improving compliance. This analysis gives organizations a clear picture of their data age distribution, allowing for targeted information lifecycle management. Storage administrators can apply tiering policies based on access patterns, compliance teams can implement appropriate retention controls, and end users benefit from reduced clutter in active storage locations.",
      "action": "Implement policies for each lifecycle stage (retention, archiving, deletion).",
      "verified": true,
      "visualization": false,
      "keywords": [
        "Lifecycle Stages",
        "Data Age Distribution",
        "Active Data",
        "Aging Data",
        "Inactive Data",
        "Archival Data",
        "Lifecycle Management",
        "Data Tiering Policies",
        "Retention Controls",
        "Data Compliance",
        "Storage Costs",
        "Information Management",
        "Storage Optimization",
        "Data Clutter Reduction",
        "Access Patterns",
        "IT Governance",
        "Data Retention Policies",
        "Efficient Data Use"
      ],
      "modified": "2025-04-13T11:09:39.752960"
    },
    {
      "id": "custom_metadata_analysis",
      "title": "Custom Metadata Quality",
      "category": "Governance Lifecycle",
      "purpose": "Evaluates the presence and quality of custom metadata fields across files.",
      "query": "SELECT \n  CASE\n    WHEN metadata IS NULL THEN 'Missing Metadata'\n    WHEN metadata = '{}' THEN 'Empty Metadata'\n    WHEN LENGTH(metadata) < 50 THEN 'Minimal Metadata'\n    WHEN LENGTH(metadata) < 200 THEN 'Basic Metadata'\n    ELSE 'Rich Metadata'\n  END as \"Metadata Quality\",\n  COUNT(name) as \"File Count\",\n  AVG(LENGTH(metadata)) as \"Average Metadata Length\"\nWHERE \n  ClassID = 'idxobject'\nGROUP BY \n  CASE\n    WHEN metadata IS NULL THEN 'Missing Metadata'\n    WHEN metadata = '{}' THEN 'Empty Metadata'\n    WHEN LENGTH(metadata) < 50 THEN 'Minimal Metadata'\n    WHEN LENGTH(metadata) < 200 THEN 'Basic Metadata'\n    ELSE 'Rich Metadata'\n  END",
      "impact": "Poor metadata directly impacts productivity - knowledge workers spend an average of 2.5 hours per week searching for information they never find. This analysis helps identify where metadata enrichment will have the greatest impact. Organizations that improve metadata quality report 30-40% improvements in data discoverability and usability. Users spend less time searching and more time using information effectively, while governance teams can focus enrichment efforts on high-value content.",
      "action": "Identify data with poor metadata quality for enrichment.",
      "verified": true,
      "visualization": false,
      "keywords": [
        "Metadata Quality",
        "Custom Metadata",
        "Missing Metadata",
        "Empty Metadata",
        "Minimal Metadata",
        "Basic Metadata",
        "Rich Metadata",
        "Data Discoverability",
        "Metadata Enrichment",
        "Productivity Impact",
        "Governance Teams",
        "High-Value Content",
        "Data Usability",
        "Information Management",
        "Knowledge Workers",
        "Data Classification",
        "Retention Policies",
        "Metadata Analysis"
      ],
      "modified": "2025-04-13T11:10:13.774958"
    },
    {
      "id": "data_management_responsibility_by_owner",
      "title": "Data Management Responsibility by Owner",
      "category": "Governance Lifecycle",
      "purpose": "Shows how data management responsibility is distributed across users.",
      "query": "SELECT \n  osOwner as \"Owner\",\n  COUNT(name) as \"Total Files\",\n  SUM(CASE WHEN classification IS NULL OR classification = '' THEN 1 ELSE 0 END) as \"Unclassified Files\",\n  SUM(CASE WHEN classification IS NOT NULL AND classification != '' THEN 1 ELSE 0 END) as \"Classified Files\",\n  (SUM(CASE WHEN classification IS NOT NULL AND classification != '' THEN 1 ELSE 0 END) * 100.0 / \n    CASE WHEN COUNT(name) = 0 THEN 1 ELSE COUNT(name) END) as \"Classification Rate (%)\",\n  SUM(size)/1048576 as \"Total Size (MB)\"\nWHERE \n  osOwner IS NOT NULL\n  AND osOwner != ''\n  AND ClassID = 'idxobject'\nGROUP BY \n  osOwner\nORDER BY \n  COUNT(name) DESC;",
      "impact": "User-level analysis identifies governance training opportunities with precision. Rather than broad training programs, this approach allows targeted education where it matters most. Organizations using this focused approach typically improve classification compliance by 40-60%, while reducing training costs by 25-35%. Individual users receive guidance relevant to their specific data management practices, while governance teams can track improvement metrics at both individual and organizational levels.",
      "action": "Target data governance training for users with low classification rates.",
      "verified": true,
      "visualization": false,
      "keywords": [
        "Data Management",
        "User Responsibility",
        "Classification Compliance",
        "Governance Training",
        "Targeted Education",
        "Precision Analysis",
        "Training Costs Reduction",
        "Data Classification",
        "Unclassified Files",
        "Classified Files",
        "File Count Analysis",
        "Ownership Metrics",
        "Organizational Improvement",
        "Governance Leaders",
        "Data Protection",
        "Corporate Security",
        "User-Level Insights",
        "Training Optimization"
      ],
      "modified": "2025-04-13T11:15:42.503238"
    },
    {
      "id": "lifecycle_rule_compliance",
      "title": "Lifecycle Rule Adherence",
      "category": "Governance Lifecycle",
      "purpose": "Analyzes adherence to data lifecycle rules based on age, type, and classification.",
      "query": "-- Query uses date template variables which will be automatically replaced with actual dates\n-- based on the current date when the query is executed.\n-- As of today (2025-03-25):\n--   {{DATE_MINUS_3_MONTHS}} = 2024-12-25 (for temporary files)\n--   {{DATE_MINUS_1_YEAR}} = 2024-03-25 (for confidential data)\n--   {{DATE_MINUS_2_YEARS}} = 2023-03-25 (for restricted data)\n--   {{DATE_MINUS_5_YEARS}} = 2020-03-25 (for public data)\nSELECT \n  CASE\n    WHEN classification LIKE '%Confidential%' AND modifyTime < '{{DATE_MINUS_1_YEAR}}' THEN 'Confidential Retention Violation' -- older than 1 year\n    WHEN classification LIKE '%Restricted%' AND modifyTime < '{{DATE_MINUS_2_YEARS}}' THEN 'Restricted Retention Violation'   -- older than 2 years\n    WHEN classification LIKE '%Public%' AND modifyTime < '{{DATE_MINUS_5_YEARS}}' THEN 'Public Retention Violation'        -- older than 5 years\n    WHEN extension IN ('log','tmp','temp') AND modifyTime < '{{DATE_MINUS_3_MONTHS}}' THEN 'Temporary File Violation'    -- older than 3 months\n    ELSE 'Compliant'\n  END as \"Compliance Status\",\n  COUNT(name) as \"File Count\",\n  SUM(size)/1048576 as \"Total Size (MB)\"\nWHERE \n  (ClassID = 'idxobject')\nGROUP BY \n  CASE\n    WHEN classification LIKE '%Confidential%' AND modifyTime < '{{DATE_MINUS_1_YEAR}}' THEN 'Confidential Retention Violation'\n    WHEN classification LIKE '%Restricted%' AND modifyTime < '{{DATE_MINUS_2_YEARS}}' THEN 'Restricted Retention Violation'\n    WHEN classification LIKE '%Public%' AND modifyTime < '{{DATE_MINUS_5_YEARS}}' THEN 'Public Retention Violation'\n    WHEN extension IN ('log','tmp','temp') AND modifyTime < '{{DATE_MINUS_3_MONTHS}}' THEN 'Temporary File Violation'\n    ELSE 'Compliant'\n  END\nHAVING \n  \"Compliance Status\" != 'Compliant'\nORDER BY \n  \"File Count\" DESC;",
      "impact": "Lifecycle rule violations create both risk and waste - costing organizations an average of $10-20 per GB per year in unnecessary storage and backup costs. This query automates the identification of non-compliant data, reducing manual discovery effort by 70-85%. Legal teams can demonstrate defensible deletion practices, records managers can maintain proper retention compliance, and storage costs decrease as data properly flows through its lifecycle.",
      "keywords": [
        "Lifecycle Rules",
        "Data Compliance",
        "Retention Policies",
        "Data Classification",
        "Confidential Data",
        "Restricted Data",
        "Public Data",
        "Temporary Files",
        "Retention Violations",
        "Storage Costs",
        "Defensible Deletion",
        "Compliance Analysis",
        "Legal Teams",
        "Records Managers",
        "Data Management",
        "Storage Optimization",
        "Manual Discovery Reduction",
        "Corporate Governance",
        "Non-compliant Data"
      ],
      "action": "Address files violating retention policies based on their classification.",
      "verified": true,
      "visualization": false
    },
    {
      "id": "inconsistent_metadata_analysis",
      "title": "Inconsistent Metadata Analysis",
      "category": "Governance Lifecycle",
      "purpose": "Identifies files with inconsistent or mismatched metadata that may need correction.",
      "query": "SELECT \n  parentPath as \"Path\",\n  name as \"File Name\", \n  classification as \"Classification\",\n  extension as \"Extension\",\n  'Classification-Extension Mismatch' as \"Issue Type\"\nWHERE \n  (\n    (classification LIKE '%Document%' AND extension NOT IN ('doc','docx','pdf','txt','rtf','odt'))\n    OR (classification LIKE '%Image%' AND extension NOT IN ('jpg','jpeg','png','gif','bmp','tiff'))\n    OR (classification LIKE '%Video%' AND extension NOT IN ('mp4','avi','mov','wmv','flv','mkv'))\n    OR (classification LIKE '%Audio%' AND extension NOT IN ('mp3','wav','ogg','aac','wma'))\n    OR (classification LIKE '%Code%' AND extension NOT IN ('py','java','js','c','cpp','h','cs','php','html'))\n  )\n  AND ClassID = 'idxobject';",
      "impact": "Inconsistent metadata leads to poor search results and unreliable governance - organizations with high metadata consistency report 60-75% higher user satisfaction with enterprise search. This query identifies specific inconsistencies that would otherwise be invisible in aggregate reports. Content managers can correct metadata problems systematically rather than anecdotally, while end users benefit from more accurate search results and properly applied retention policies.",
      "action": "Fix inconsistent metadata to improve search and governance.",
      "keywords": [
        "Inconsistent Metadata",
        "Metadata Mismatch",
        "Classification Issues",
        "Extension Errors",
        "Data Governance",
        "Enterprise Search",
        "Search Accuracy",
        "Retention Policies",
        "Systematic Corrections",
        "Content Managers",
        "Data Usability",
        "Metadata Consistency",
        "Knowledge Workers",
        "File Classification",
        "File Metadata Analysis",
        "Governance Improvements",
        "User Satisfaction",
        "Information Management"
      ],
      "verified": true,
      "visualization": false
    },
    {
      "id": "governance_improvement_opportunities3",
      "title": "Where to Improve Governance - Files without Source Information",
      "category": "Governance Lifecycle",
      "purpose": "Provides a summary of key areas for improving governance across the data estate.",
      "query": "SELECT \n  'Files Without Source Information' as \"Governance Gap\",\n  COUNT(name) as \"Count\"\nWHERE \n  (source IS NULL OR source = '')\n  AND ClassID = 'idxobject'\n\nGROUP BY \n  \"Governance Gap\";",
      "impact": "This holistic view of governance gaps allows for data-driven prioritization of improvement initiatives. Organizations using this approach to guide their governance roadmap typically achieve 2.5-3x ROI on their governance investments compared to those following conventional wisdom or vendor suggestions. Executives gain a clear understanding of governance maturity, compliance teams can document ongoing governance improvement efforts for regulators, and IT teams align their technical implementations with business governance priorities.",
      "action": "Focus governance improvement efforts on the gaps with highest percentages.",
      "verified": true,
      "visualization": false,
      "keywords": [
        "Governance Gaps",
        "Holistic View",
        "Metadata Quality",
        "Improvement Initiatives",
        "Data Governance",
        "Governance Maturity",
        "Compliance Documentation",
        "Technical Implementations",
        "Business Priorities",
        "ROI Maximization",
        "Governance Roadmap",
        "Regulatory Compliance",
        "IT Alignment",
        "Priority Actions",
        "Enterprise Data",
        "Governance Strategies",
        "Data-driven Decisions"
      ],
      "modified": "2025-04-13T11:26:50.084865"
    },
    {
      "id": "governance_improvement_opportunities0",
      "title": "Where to Improve Governance - Unclassified Files",
      "category": "Governance Lifecycle",
      "purpose": "Provides a summary of key areas for improving governance across the data estate.",
      "query": "SELECT \n  'Unclassified Files' as \"Governance Gap\",\n  COUNT(name) as \"Count\"\nWHERE \n  (classification IS NULL OR classification = '')\n  AND ClassID = 'idxobject'\nGROUP BY \n  \"Governance Gap\"",
      "impact": "This holistic view of governance gaps allows for data-driven prioritization of improvement initiatives. Organizations using this approach to guide their governance roadmap typically achieve 2.5-3x ROI on their governance investments compared to those following conventional wisdom or vendor suggestions. Executives gain a clear understanding of governance maturity, compliance teams can document ongoing governance improvement efforts for regulators, and IT teams align their technical implementations with business governance priorities.",
      "action": "Focus governance improvement efforts on the gaps with highest percentages.",
      "verified": true,
      "keywords": [
        "Governance Gaps",
        "Holistic View",
        "Metadata Quality",
        "Improvement Initiatives",
        "Data Governance",
        "Governance Maturity",
        "Compliance Documentation",
        "Technical Implementations",
        "Business Priorities",
        "ROI Maximization",
        "Governance Roadmap",
        "Regulatory Compliance",
        "IT Alignment",
        "Priority Actions",
        "Enterprise Data",
        "Governance Strategies",
        "Data-driven Decisions"
      ],
      "visualization": false
    },
    {
      "id": "governance_improvement_opportunities1",
      "title": "Where to Improve Governance - Files Without Owner",
      "category": "Governance Lifecycle",
      "purpose": "Provides a summary of key areas for improving governance across the data estate.",
      "query": "SELECT \n  'Files Without Owner' as \"Governance Gap\",\n  COUNT(name) as \"Count\"\nWHERE \n  (osOwner IS NULL OR osOwner = '')\n  AND ClassID = 'idxobject'\n\n\nGROUP BY \n  \"Governance Gap\"",
      "impact": "This holistic view of governance gaps allows for data-driven prioritization of improvement initiatives. Organizations using this approach to guide their governance roadmap typically achieve 2.5-3x ROI on their governance investments compared to those following conventional wisdom or vendor suggestions. Executives gain a clear understanding of governance maturity, compliance teams can document ongoing governance improvement efforts for regulators, and IT teams align their technical implementations with business governance priorities.",
      "action": "Focus governance improvement efforts on the gaps with highest percentages.",
      "keywords": [
        "Governance Gaps",
        "Holistic View",
        "Metadata Quality",
        "Improvement Initiatives",
        "Data Governance",
        "Governance Maturity",
        "Compliance Documentation",
        "Technical Implementations",
        "Business Priorities",
        "ROI Maximization",
        "Governance Roadmap",
        "Regulatory Compliance",
        "IT Alignment",
        "Priority Actions",
        "Enterprise Data",
        "Governance Strategies",
        "Data-driven Decisions"
      ],
      "verified": true,
      "visualization": false
    },
    {
      "id": "governance_improvement_opportunities2",
      "title": "Where to Improve Governance - Files With Minimal Metadata",
      "category": "Governance Lifecycle",
      "purpose": "Provides a summary of key areas for improving governance across the data estate.",
      "query": "SELECT \n  'Files With Minimal Metadata' as \"Governance Gap\",\n  COUNT(name) as \"Count\"\nWHERE \n  (metadata IS NULL OR metadata = '{}' OR LENGTH(metadata) < 50)\n  AND ClassID = 'idxobject'\nGROUP BY \n  \"Governance Gap\"",
      "impact": "This holistic view of governance gaps allows for data-driven prioritization of improvement initiatives. Organizations using this approach to guide their governance roadmap typically achieve 2.5-3x ROI on their governance investments compared to those following conventional wisdom or vendor suggestions. Executives gain a clear understanding of governance maturity, compliance teams can document ongoing governance improvement efforts for regulators, and IT teams align their technical implementations with business governance priorities.",
      "action": "Focus governance improvement efforts on the gaps with highest percentages.",
      "keywords": [
        "Governance Gaps",
        "Holistic View",
        "Metadata Quality",
        "Improvement Initiatives",
        "Data Governance",
        "Governance Maturity",
        "Compliance Documentation",
        "Technical Implementations",
        "Business Priorities",
        "ROI Maximization",
        "Governance Roadmap",
        "Regulatory Compliance",
        "IT Alignment",
        "Priority Actions",
        "Enterprise Data",
        "Governance Strategies",
        "Data-driven Decisions"
      ],
      "verified": true,
      "visualization": false,
      "modified": "2025-04-13T13:16:59.510343"
    },
    {
      "id": "classification_confidence_analysis",
      "title": "Check Classification Reliability",
      "category": "Governance Lifecycle",
      "purpose": "Identifies files with classifications and their confidence levels to assess the reliability of applied classifications.",
      "query": "SELECT\n  CASE\n    WHEN classification IS NULL THEN 'Unclassified'\n    WHEN classification = '' THEN 'Unclassified'\n    WHEN classification LIKE '%unclassified%' THEN 'Unclassified'\n    WHEN confidence >= 90 THEN 'High Confidence (90-100)'\n    WHEN confidence >= 75 THEN 'Medium Confidence (75-89)'\n    WHEN confidence >= 50 THEN 'Low Confidence (50-74)'\n    WHEN confidence > 0 THEN 'Very Low Confidence (<50)'\n    ELSE 'No Confidence Score'\n  END as \"Confidence Level\",\n  COUNT(name) as \"File Count\",\n  SUM(size)/1048576 as \"Total Size (MB)\"\nWHERE\n  ClassID = 'idxobject'\nGROUP BY\n  CASE\n    WHEN classification IS NULL THEN 'Unclassified'\n    WHEN classification = '' THEN 'Unclassified'\n    WHEN classification LIKE '%unclassified%' THEN 'Unclassified'\n    WHEN confidence >= 90 THEN 'High Confidence (90-100)'\n    WHEN confidence >= 75 THEN 'Medium Confidence (75-89)'\n    WHEN confidence >= 50 THEN 'Low Confidence (50-74)'\n    WHEN confidence > 0 THEN 'Very Low Confidence (<50)'\n    ELSE 'No Confidence Score'\n  END",
      "impact": "Understanding classification confidence helps organizations prioritize manual review efforts and improve overall accuracy. Organizations using confidence thresholds to guide verification typically improve classification quality by 30-45% while reducing false positives by 25-40%. Governance teams gain clearer visibility into operational classification quality, allowing for more precise tuning of automated systems and better allocation of human review resources. Security teams avoid alert fatigue by focusing on high-confidence classifications for sensitive data.",
      "action": "Manually verify classifications with low confidence scores and consider adjusting classification thresholds.",
      "verified": true,
      "visualization": false,
      "keywords": [
        "Classification Confidence",
        "Confidence Levels",
        "Data Reliability",
        "Manual Review",
        "Data Accuracy",
        "Classification Quality",
        "False Positives",
        "Governance Teams",
        "Security Teams",
        "Automated Systems",
        "Human Review",
        "Sensitive Data",
        "Verification Priorities",
        "Threshold Adjustments",
        "Operational Quality",
        "Alert Fatigue",
        "Data Management",
        "Corporate Governance"
      ],
      "modified": "2025-04-13T11:30:58.002977"
    },
    {
      "id": "large_email_attachments",
      "title": "Find Large Email Attachments",
      "category": "Email Analysis",
      "purpose": "Identifies emails with unusually large attachments that may be consuming excessive storage.",
      "query": "SELECT \n  name as \"File Name\",\n  --metadataObject.[\"Message-From\"] as \"Sender\",\n  --metadataObject.[\"dc:subject\"] as \"Subject\",\n  size as \"Size (Bytes)\",\n  size/1048576 as \"Size (MB)\"--,\n  --metadataObject.[\"dcterms:created\"] as \"Date\"\nWHERE \n  extension = 'eml' \n  AND ClassID = 'idxobject'\n  AND metadata LIKE ('%\"Multipart-Subtype\":\"mixed\"%')\n  AND size > 10485760 -- larger than 10MB\nORDER BY\n  size DESC;",
      "impact": "Large email attachments typically consume 35-45% of email storage despite representing only 5-10% of message count. This query helps identify specific storage reduction opportunities with minimal user impact. IT departments implementing attachment size policies based on this analysis reduce email storage costs by 20-30% annually. Users benefit from improved email system performance and fewer mailbox quota issues, while maintaining access to important content.",
      "action": "Consider storage optimization policies for large email attachments.",
      "keywords": [
        "large email attachments",
        "email storage optimization",
        "oversized email analysis",
        "reducing email storage costs",
        "email system performance improvement",
        "identifying large attachments",
        "storage-heavy emails",
        "cleaning up large emails",
        "email metadata search",
        "email attachment policies"
      ],
      "notes": "unable to add metadata fields without column",
      "verified": true,
      "visualization": false,
      "modified": "2025-04-19T14:24:30.460238"
    },
    {
      "id": "document_length_analysis",
      "title": "1. Document Length Analysis",
      "category": "Content Analytics",
      "purpose": "Analyzes the length/size distribution of document types to understand content complexity.",
      "query": "SELECT \n  extension as \"Document Type\",\n  COUNT(name) as \"Document Count\",\n  AVG(size) as \"Average Size (Bytes)\",\n  MIN(size) as \"Smallest Document\",\n  MAX(size) as \"Largest Document\"\nWHERE \n  extension IN ('doc','docx','pdf','txt','rtf','md','html')\n  AND ClassID = 'idxobject'\nGROUP BY \n  extension\nORDER BY \n  AVG(size) DESC;",
      "impact": "Document length analysis reveals opportunities to optimize content structure and storage. Organizations implementing document optimization based on this analysis typically reduce document storage requirements by 15-25%. Knowledge workers benefit from more concise, usable content, spending 20% less time searching through lengthy documents. Content creators receive targeted guidance on optimal document length based on actual usage patterns rather than arbitrary guidelines.",
      "action": "Identify document types with excessive size for potential optimization.",
      "keywords": [
        "Document Length Analysis",
        "Size Distribution",
        "Content Complexity",
        "Document Optimization",
        "Storage Requirements",
        "Knowledge Workers",
        "Content Usability",
        "Document Types",
        "Excessive Size",
        "Optimized Content",
        "Usage Patterns",
        "Guidance for Creators",
        "Storage Efficiency",
        "Lengthy Documents",
        "Retention Policies",
        "Enterprise Content",
        "Efficiency Gains",
        "Data Management"
      ],
      "verified": true,
      "visualization": false,
      "modified": "2025-04-13T13:13:08.091717"
    },
    {
      "id": "content_category_analysis",
      "title": "Content Category Analysis",
      "category": "Content Analysis",
      "purpose": "Analyzes the distribution of document categories or subjects across the content repository.",
      "query": "SELECT \n  --metadataObject.[\"dc:subject\"] as \"Document Category\",\n  metadataObject--,\n--  COUNT(name) as \"Document Count\",\n  --COUNT(DISTINCT extension) as \"Format Types\",\n  --COUNT(DISTINCT osOwner) as \"Author Count\"\nWHERE \n  metadata LIKE ('%\"dc:subject\"%')\n--  AND metadataObject.[\"dc:subject\"] IS NOT NULL\n -- AND metadataObject.[\"dc:subject\"] != ''\n  AND ClassID = 'idxobject'\n--GROUP BY \n -- metadataObject.[\"dc:subject\"]\n--ORDER BY \n -- COUNT(name) DESC;",
      "impact": "Content categorization is the foundation of effective information architecture. This query provides visibility into how content is actually categorized versus theoretical taxonomies. Information architects can align formal taxonomies with actual usage patterns, typically improving findability by 35-50%. Users experience more intuitive information organization, while governance teams can ensure sensitive content has appropriate categorization for security and compliance purposes.",
      "action": "Review subject categorization for taxonomy alignment and completeness.",
      "keywords": [],
      "notes": "needs metadataObject JSON thing, .[\"dc:subject\"] as \"Document Category\" ",
      "verified": true,
      "visualization": false,
      "modified": "2025-04-19T14:55:04.270463"
    },
    {
      "id": "text_content_type_analysis",
      "title": "Text Content Type Analysis",
      "category": "Content Analytics",
      "purpose": "Identifies documents likely to contain specific types of content based on keywords.",
      "query": "SELECT \n  CASE\n    WHEN (\n      metadata LIKE ('%policy%') OR \n      metadata LIKE ('%procedure%') OR\n      name LIKE '%policy%' OR\n      name LIKE '%procedure%'\n    ) THEN 'Policy/Procedure'\n    \n    WHEN (\n      metadata LIKE ('%report%') OR\n      metadata LIKE ('%analysis%') OR\n      name LIKE '%report%' OR\n      name LIKE '%analysis%'\n    ) THEN 'Report/Analysis'\n    \n    WHEN (\n      metadata LIKE ('%proposal%') OR\n      metadata LIKE ('%pitch%') OR\n      name LIKE '%proposal%' OR\n      name LIKE '%pitch%'\n    ) THEN 'Proposal/Pitch'\n    \n    WHEN (\n      metadata LIKE ('%contract%') OR\n      metadata LIKE ('%agreement%') OR\n      name LIKE '%contract%' OR\n      name LIKE '%agreement%'\n    ) THEN 'Contract/Agreement'\n    \n    WHEN (\n      metadata LIKE ('%presentation%') OR\n      metadata LIKE ('%slides%') OR\n      extension IN ('ppt','pptx') OR\n      name LIKE '%presentation%'\n    ) THEN 'Presentation'\n    \n    ELSE 'Other'\n  END as \"Content Type\",\n  COUNT(name) as \"Document Count\",\n  SUM(size)/1048576 as \"Total Size (MB)\"\nWHERE \n  ClassID = 'idxobject'\n  AND extension IN ('doc','docx','pdf','txt','rtf','ppt','pptx')\nGROUP BY \n  CASE\n    WHEN (\n      metadata LIKE ('%policy%') OR \n      metadata LIKE ('%procedure%') OR\n      name LIKE '%policy%' OR\n      name LIKE '%procedure%'\n    ) THEN 'Policy/Procedure'\n    \n    WHEN (\n      metadata LIKE ('%report%') OR\n      metadata LIKE ('%analysis%') OR\n      name LIKE '%report%' OR\n      name LIKE '%analysis%'\n    ) THEN 'Report/Analysis'\n    \n    WHEN (\n      metadata LIKE ('%proposal%') OR\n      metadata LIKE ('%pitch%') OR\n      name LIKE '%proposal%' OR\n      name LIKE '%pitch%'\n    ) THEN 'Proposal/Pitch'\n    \n    WHEN (\n      metadata LIKE ('%contract%') OR\n      metadata LIKE ('%agreement%') OR\n      name LIKE '%contract%' OR\n      name LIKE '%agreement%'\n    ) THEN 'Contract/Agreement'\n    \n    WHEN (\n      metadata LIKE ('%presentation%') OR\n      metadata LIKE ('%slides%') OR\n      extension IN ('ppt','pptx') OR\n      name LIKE '%presentation%'\n    ) THEN 'Presentation'\n    \n    ELSE 'Other'\n  END\nORDER BY \n  COUNT(name) DESC;",
      "impact": "Understanding content type distribution enables targeted management strategies for different document categories. This query helps organizations implement appropriate workflows and policies based on content purpose rather than format. Records management teams can apply retention rules based on content type, improving compliance by 40-60%. Content creators benefit from templates and guidelines specific to each content category, while users find information organized by purpose rather than arbitrary technical classifications.",
      "action": "Implement more structured content categorization based on actual usage patterns.",
      "keywords": [
        "Content Type Distribution",
        "Document Categories",
        "Keywords Identification",
        "Policy Documents",
        "Procedure Guidelines",
        "Reports",
        "Analysis Files",
        "Proposals",
        "Pitches",
        "Contracts",
        "Agreements",
        "Presentations",
        "Retention Rules",
        "Compliance Improvement",
        "Workflow Optimization",
        "Content Templates",
        "Guidelines Enforcement",
        "Technical Classifications"
      ],
      "verified": true,
      "visualization": false
    }
  ]
}